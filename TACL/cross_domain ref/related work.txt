Our idea & contribution:

do not need to train the shared general knowledge on new database with different schemas; tagging query with placeholder based on embedded schema information, using seq2seq_bridging model (a new model) and directly transform to SQL command; a new dataset, data augmentation based on Wikitable; cross-domain transfer-learnable NLIDB, Geo880 (Overnight), the SQL logical form could be deterministically generated from the lambda expression.

1. The overnight 2015 ACL paper:

analyze grammar and generate paraphrases to increse to data size; not seq2seq


2. 1704 Cross-domain Semantic Parsing via Paraphrasing

We use natural language as an intermediate representation to transfer knowledge across domains; seq2seq model for paraphrase.
Domain adaptation protocol. We will use the following protocol: (1) train a paraphrase model using the data of the source domain, (2) use the learned parameters to initialize a model in the target domain, and (3) fine-tune the model using the training data of the target domain.

3. 1702
Herzig and Berant (2017) have explored another direction of semantic parsing with multiple domains, where they use all the domains to train a single semantic parser, and attach a domain-specific encoding to the training data of each domain to help the semantic parser differentiate between domains. 


******************************
Note:
canonical utterance: intermediate sentence representation (still natural language, nearly the same, but more fixed format)