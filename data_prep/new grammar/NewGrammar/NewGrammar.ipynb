{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Grammar Version 2.0\n",
    "Edit and use for generate the 2nd version grammar archive 0507"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "length = 3, total examples: 21\n",
      "length = 5, total examples: 13\n",
      "length = 6, total examples: 148\n",
      "length = 7, total examples: 78\n",
      "length = 10, total examples: 86\n",
      "length = 11, total examples: 65\n",
      "length = 13, total examples: 1\n",
      "length = 14, total examples: 1\n",
      "length = 15, total examples: 23\n",
      "length = 19, total examples: 75\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "def renew19(line):\n",
    "    tokens = line.split()\n",
    "    newtokens = [x for x in tokens[:-1]]\n",
    "    newtokens[0] = tokens[16]\n",
    "    newtokens[1:3] = ['A', 'as']\n",
    "    newtokens[3:5] = tokens[4:6]\n",
    "    newtokens[5:9] = tokens[0:4]\n",
    "    newtokens[9:12] = ['and', 'B', 'as']\n",
    "    #newtokens[12:14] = tokens[12:14]\n",
    "    newtokens[14:] = tokens[8:12]\n",
    "    \n",
    "    if newtokens[0] == 'mean':\n",
    "        newtokens[0] = 'avg'\n",
    "    newline = ' '.join(newtokens)\n",
    "    return newline\n",
    "\n",
    "def renew15(line):\n",
    "    tokens = line.split()\n",
    "    newtokens = [x for x in tokens[:-1]]\n",
    "    newtokens[0:3] = tokens[12:]\n",
    "    newtokens[3:7] = tokens[8:12]\n",
    "    newtokens[7] = 'as'\n",
    "    newtokens[8:10] = tokens[4:6]\n",
    "    newtokens[10:] = tokens[0:4]\n",
    "    newline = ' '.join(newtokens)\n",
    "    return newline\n",
    "\n",
    "def renew14(line):\n",
    "    tokens = line.split()\n",
    "    newtokens = [x for x in tokens[:-1]]\n",
    "    newtokens[0:2] = tokens[12:]\n",
    "    newtokens[2:6] = tokens[8:12]\n",
    "    newtokens[6] = 'as'\n",
    "    newtokens[7:9] = tokens[4:6]\n",
    "    newtokens[9:] = tokens[0:4]\n",
    "    newline = ' '.join(newtokens)\n",
    "    return newline\n",
    "\n",
    "def renew13(line):\n",
    "    tokens = line.split()\n",
    "    newtokens = [x for x in tokens[:-1]]\n",
    "    newtokens[0] = tokens[10]\n",
    "    newtokens[1:3] = ['A', 'as']\n",
    "    newtokens[3:6] = tokens[0:3]\n",
    "    newtokens[6:9] = ['and','B', 'as']\n",
    "    newtokens[9:] = tokens[5:8]\n",
    "    newline = ' '.join(newtokens)\n",
    "    return newline\n",
    "\n",
    "def renew11(line):\n",
    "    tokens = line.split()\n",
    "    newtokens = [x for x in tokens]\n",
    "    newtokens[0:3] = tokens[8:]\n",
    "    newtokens[3:7] = tokens[0:4]\n",
    "    newtokens[7] = 'and'\n",
    "    newtokens[8:] = tokens[5:8]\n",
    "    newline = ' '.join(newtokens)\n",
    "    return newline\n",
    "\n",
    "def renew10(line):\n",
    "    tokens = line.split()\n",
    "    newtokens = [x for x in tokens]\n",
    "    newtokens[0:2] = tokens[8:]\n",
    "    newtokens[2:6] = tokens[0:4]\n",
    "    newtokens[6] = 'and'\n",
    "    newtokens[7:] = tokens[5:8]\n",
    "    newline = ' '.join(newtokens)\n",
    "    return newline\n",
    "\n",
    "def renew7(line):\n",
    "    tokens = line.split()\n",
    "    newtokens = [x for x in tokens]\n",
    "    newtokens[0:3] = tokens[4:]\n",
    "    newtokens[3:] = tokens[0:4]\n",
    "    newline = ' '.join(newtokens)\n",
    "    return newline\n",
    "\n",
    "def renew6(line):\n",
    "    tokens = line.split()\n",
    "    newtokens = [x for x in tokens]\n",
    "    newtokens[0:2] = tokens[4:]\n",
    "    newtokens[2:] = tokens[0:4]\n",
    "    \n",
    "    if newtokens[0] == 'mean':\n",
    "        newtokens[0] = 'avg'\n",
    "    newline = ' '.join(newtokens)\n",
    "    return newline\n",
    "\n",
    "def renew5(line):\n",
    "    tokens = line.split()\n",
    "    newtokens = [x for x in tokens]\n",
    "    newtokens[0] = 'count'\n",
    "    newtokens[1:] = tokens[0:4]\n",
    "    newline = ' '.join(newtokens)\n",
    "    return newline\n",
    "\n",
    "len_search = dict()\n",
    "f2 = open('./rand_test2.lo','w')\n",
    "with open('./rand_test.lo') as f:\n",
    "    for line in f:\n",
    "        tokens = line.split()\n",
    "        length = len(tokens)\n",
    "        if length not in len_search:\n",
    "            len_search[length] = []\n",
    "        len_search[length].append(line)\n",
    "        if length == 19:\n",
    "            newline = renew19(line)\n",
    "            f2.write(newline+'\\n')\n",
    "        elif length == 15:\n",
    "            newline = renew15(line)\n",
    "            f2.write(newline+'\\n')\n",
    "        elif length == 14:\n",
    "            newline = renew14(line)\n",
    "            f2.write(newline+'\\n')\n",
    "        elif length == 13:\n",
    "            newline = renew13(line)\n",
    "            f2.write(newline+'\\n')\n",
    "        elif length == 11:\n",
    "            newline = renew11(line)\n",
    "            f2.write(newline+'\\n')\n",
    "        elif length == 10:\n",
    "            newline = renew10(line)\n",
    "            f2.write(newline+'\\n')\n",
    "        elif length == 7:\n",
    "            newline = renew7(line)\n",
    "            f2.write(newline+'\\n')\n",
    "        elif length == 6:\n",
    "            newline = renew6(line)\n",
    "            f2.write(newline+'\\n')\n",
    "        elif length == 5:\n",
    "            newline = renew5(line)\n",
    "            f2.write(newline+'\\n')\n",
    "        else:\n",
    "            f2.write(line)\n",
    "f2.close()\n",
    "\n",
    "for key in len_search.keys():\n",
    "    value = len_search[key]\n",
    "    print 'length = %d, total examples: %d' %(key, len(value))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Grammar Version 3.0\n",
    "Used for generate new version of grammar (shorter version for sum, diff, avg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def renew19(line):\n",
    "    ''' from 19 to 11\n",
    "    '''\n",
    "    tokens = line.split()\n",
    "    # newly changed\n",
    "    # 'sum {comp_field1} where {comp_field2} {comp} {comp_val} and where {comp_field2} {comp} {query2_comp_val} '\n",
    "    newtokens = [x for x in tokens[:11]]\n",
    "    newtokens[0] = tokens[16]\n",
    "    newtokens[1] = tokens[5]\n",
    "    newtokens[2:6] = tokens[0:4]\n",
    "    newtokens[6] = 'and'\n",
    "    newtokens[7] = 'where'\n",
    "    #newtokens[12:14] = tokens[12:14]\n",
    "    newtokens[8:11] = tokens[9:12]\n",
    "    \n",
    "    if newtokens[0] == 'mean':\n",
    "        newtokens[0] = 'avg'\n",
    "    newline = ' '.join(newtokens)\n",
    "    return newline\n",
    "\n",
    "def renew15(line):\n",
    "    ''' from 15 to 14\n",
    "    '''\n",
    "    tokens = line.split()\n",
    "    newtokens = [x for x in tokens[:-1]]\n",
    "    newtokens[0:3] = tokens[12:]\n",
    "    newtokens[3:7] = tokens[8:12]\n",
    "    newtokens[7] = 'as'\n",
    "    newtokens[8:10] = tokens[4:6]\n",
    "    newtokens[10:] = tokens[0:4]\n",
    "    newline = ' '.join(newtokens)\n",
    "    return newline\n",
    "\n",
    "def renew14(line):\n",
    "    ''' before/after type, from 14 to 6\n",
    "        New grammar: next and prev (at the position of where)\n",
    "    '''\n",
    "    tokens = line.split()\n",
    "    # newly change\n",
    "    newtokens = [x for x in tokens[:9]]\n",
    "    newtokens[0:2] = tokens[12:]\n",
    "    newtokens[2:5] = tokens[8:11]\n",
    "    newtokens[5:9] = tokens[0:4]\n",
    "    newline = ' '.join(newtokens)\n",
    "    return newline\n",
    "\n",
    "def renew13(line):\n",
    "    ''' from 13 to 7\n",
    "    '''\n",
    "    tokens = line.split()\n",
    "    # newly changed: diff {comp_field1}' arg {max_min} {arg1} 'and' arg {max_min} {arg1}\n",
    "    newtokens = [x for x in tokens[:7]]\n",
    "    newtokens[0] = tokens[10]\n",
    "    newtokens[1] = tokens[1]\n",
    "    newtokens[2] = tokens[0]\n",
    "    newtokens[3] = tokens[2]\n",
    "    newtokens[4] = 'and'\n",
    "    newtokens[5] = tokens[5]\n",
    "    newtokens[6] = tokens[7]\n",
    "    newline = ' '.join(newtokens)\n",
    "    return newline\n",
    "\n",
    "def renew11(line):\n",
    "    ''' from 11 to 12\n",
    "    '''\n",
    "    tokens = line.split()\n",
    "    newtokens = [x for x in tokens]\n",
    "    newtokens[0:3] = tokens[8:]\n",
    "    newtokens[3:7] = tokens[0:4]\n",
    "    newtokens[7] = 'and'\n",
    "    newtokens[8:] = tokens[5:8]\n",
    "    \n",
    "    # newly added\n",
    "    newtokens.insert(0, 'select')\n",
    "    temp = newtokens[1]\n",
    "    newtokens[1] = newtokens[2]\n",
    "    newtokens[2] = temp\n",
    "    newline = ' '.join(newtokens)\n",
    "    return newline\n",
    "\n",
    "def renew10(line):\n",
    "    tokens = line.split()\n",
    "    newtokens = [x for x in tokens]\n",
    "    newtokens[0:2] = tokens[8:]\n",
    "    newtokens[2:6] = tokens[0:4]\n",
    "    newtokens[6] = 'and'\n",
    "    newtokens[7:] = tokens[5:8]\n",
    "    newline = ' '.join(newtokens)\n",
    "    return newline\n",
    "\n",
    "def renew7(line):\n",
    "    ''' from 7 to 8\n",
    "    '''\n",
    "    tokens = line.split()\n",
    "    newtokens = [x for x in tokens]\n",
    "    newtokens[0:3] = tokens[4:]\n",
    "    newtokens[3:] = tokens[0:4]\n",
    "    \n",
    "    # newly added\n",
    "    newtokens.insert(0, 'select')\n",
    "    temp = newtokens[1]\n",
    "    newtokens[1] = newtokens[2]\n",
    "    newtokens[2] = temp\n",
    "    newline = ' '.join(newtokens)\n",
    "    return newline\n",
    "\n",
    "def renew6(line):\n",
    "    tokens = line.split()\n",
    "    newtokens = [x for x in tokens]\n",
    "    newtokens[0:2] = tokens[4:]\n",
    "    newtokens[2:] = tokens[0:4]\n",
    "    \n",
    "    if newtokens[0] == 'mean':\n",
    "        newtokens[0] = 'avg'\n",
    "    newline = ' '.join(newtokens)\n",
    "    return newline\n",
    "\n",
    "def renew5(line, schema):\n",
    "    ''' from 5 to 6\n",
    "    '''\n",
    "    tokens = line.split()\n",
    "    newtokens = [x for x in tokens]\n",
    "    newtokens[0] = 'count'\n",
    "    newtokens[1:] = tokens[0:4]\n",
    "    \n",
    "    # newly added\n",
    "    fields = schema.split()\n",
    "    newtokens.insert(1, fields[0])\n",
    "    newline = ' '.join(newtokens)\n",
    "    return newline\n",
    "\n",
    "def renew3(line):\n",
    "    ''' from 3 to 4\n",
    "    '''\n",
    "    tokens = line.split()\n",
    "    newtokens = [x for x in tokens]\n",
    "    newtokens.insert(0, 'select')\n",
    "    temp = newtokens[1]\n",
    "    newtokens[1] = newtokens[2]\n",
    "    newtokens[2] = temp\n",
    "    newline = ' '.join(newtokens)\n",
    "    return newline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "length = 2, total examples: 1\n",
      "length = 3, total examples: 111\n",
      "length = 5, total examples: 99\n",
      "length = 6, total examples: 739\n",
      "length = 7, total examples: 446\n",
      "length = 10, total examples: 490\n",
      "length = 11, total examples: 351\n",
      "length = 13, total examples: 3\n",
      "length = 14, total examples: 6\n",
      "length = 15, total examples: 109\n",
      "length = 19, total examples: 445\n",
      "Team County Wins Years_won Areas Prices\n",
      "\n",
      "which team won a year before ballymore_eustace\n",
      "\n",
      "where Team equal Ballymore_Eustace select Years_won as A where Years_won less A select Team\n",
      "\n",
      "select Team where Years_won less where Team equal Ballymore_Eustace\n",
      "Team County Wins Years_won Areas Prices\n",
      "\n",
      "which team won a year before dundalk_gael\n",
      "\n",
      "where Team equal Dundalk_Gaels select Years_won as A where Years_won less A select Team\n",
      "\n",
      "select Team where Years_won less where Team equal Dundalk_Gaels\n",
      "Team County Wins Years_won Areas Prices\n",
      "\n",
      "which team won a year before wolfe_tones\n",
      "\n",
      "where Team equal Wolfe_Tones select Years_won as A where Years_won less A select Team\n",
      "\n",
      "select Team where Years_won less where Team equal Wolfe_Tones\n",
      "Team County Wins Years_won Areas Prices\n",
      "\n",
      "which team won a year after ballymore_eustace\n",
      "\n",
      "where Team equal Ballymore_Eustace select Years_won as A where Years_won greater A select Team\n",
      "\n",
      "select Team where Years_won greater where Team equal Ballymore_Eustace\n",
      "Team County Wins Years_won Areas Prices\n",
      "\n",
      "which team won a year after wolfe_tones\n",
      "\n",
      "where Team equal Wolfe_Tones select Years_won as A where Years_won greater A select Team\n",
      "\n",
      "select Team where Years_won greater where Team equal Wolfe_Tones\n",
      "Team County Wins Years_won Areas Prices\n",
      "\n",
      "which team won a year after dundalk_gael\n",
      "\n",
      "where Team equal Dundalk_Gaels select Years_won as A where Years_won greater A select Team\n",
      "\n",
      "select Team where Years_won greater where Team equal Dundalk_Gaels\n"
     ]
    }
   ],
   "source": [
    "len_search = dict()\n",
    "qu_search = dict()\n",
    "schema_search = dict()\n",
    "with open('./rand_train.lo') as f_lo:\n",
    "    with open('../../../data/rand_train.qu') as f_qu:\n",
    "        with open('../../../data/rand_train.fi') as f_fi:\n",
    "            logic, query, schema = f_lo.readline(), f_qu.readline(), f_fi.readline()\n",
    "            while logic and query:\n",
    "                tokens = logic.split()\n",
    "                length = len(tokens)\n",
    "                if length not in len_search:\n",
    "                    len_search[length] = []\n",
    "                    schema_search[length] = []\n",
    "                    qu_search[length] = []\n",
    "                len_search[length].append(logic)\n",
    "                qu_search[length].append(query)\n",
    "                schema_search[length].append(schema)\n",
    "                logic, query, schema = f_lo.readline(), f_qu.readline(), f_fi.readline()\n",
    "for key in len_search.keys():\n",
    "    value = len_search[key]\n",
    "    print 'length = %d, total examples: %d' %(key, len(value))\n",
    "    \n",
    "count = 0\n",
    "for line in len_search[14]:\n",
    "    idx = len_search[14].index(line)\n",
    "    print schema_search[14][idx]\n",
    "    print qu_search[14][idx]\n",
    "    print line\n",
    "    newline = renew14(line)\n",
    "    print newline\n",
    "#     if len(newline.split()) == 11:\n",
    "#         count += 1\n",
    "# print count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
