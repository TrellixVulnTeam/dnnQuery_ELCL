{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data augmentation\n",
    "\n",
    "## 1 Current data statistics\n",
    "\n",
    "### We read in the files of queries, logical forms, and schema, and categorize them by length; within the same length, there would be subcategories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "length = 2, total examples: 2\n",
      "length = 4, total examples: 156\n",
      "length = 6, total examples: 1253\n",
      "length = 7, total examples: 4\n",
      "length = 8, total examples: 624\n",
      "length = 10, total examples: 687\n",
      "length = 11, total examples: 697\n",
      "length = 12, total examples: 488\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "import math\n",
    "\n",
    "logic_category_len = dict()\n",
    "query_len = dict()\n",
    "schema_len = dict()\n",
    "with open('./rand.lo') as f_lo:\n",
    "    with open('./rand.qu') as f_qu:\n",
    "        with open('./rand.fi') as f_fi:\n",
    "            logic_line, query_line, schema_line = f_lo.readline(), f_qu.readline(), f_fi.readline()\n",
    "            while logic_line and query_line and schema_line:\n",
    "                logic = logic_line.split()\n",
    "#                 if len(logic) == 13:\n",
    "#                     if logic[4] == 'less':\n",
    "#                         logic[0] = 'argmax'\n",
    "#                     else:\n",
    "#                         logic[0] = 'argmin'\n",
    "#                     logic.insert(2, logic[3])\n",
    "                length = len(logic)\n",
    "#                 if length ==0:\n",
    "#                     continue\n",
    "                if length not in logic_category_len:\n",
    "                    logic_category_len[length] = []\n",
    "                    query_len[length] = []\n",
    "                    schema_len[length] = []\n",
    "                logic_category_len[length].append(logic_line)\n",
    "                query_len[length].append(query_line)\n",
    "                schema_len[length].append(schema_line)\n",
    "                logic_line, query_line, schema_line = f_lo.readline(), f_qu.readline(), f_fi.readline()\n",
    "for key in logic_category_len.keys():\n",
    "    value = logic_category_len[key]\n",
    "    print 'length = %d, total examples: %d' %(key, len(value))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Have a look at the data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "what is the difference between the nations with the most and least amount of bronze medals\n",
      "\n",
      "how long in years has the this world series been occurring\n",
      "\n",
      "what is the difference between the nations with the most and least amount of gold medals\n",
      "\n",
      "what is the difference between the nations with the most and least amount of silver medals\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(logic_category_len[7])):\n",
    "    print query_len[7][i]\n",
    "    #print logic_category_len[14][i]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now we collect all different schema in a list for later use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nation Rank Gold Silver Bronze Total\n",
      "\n",
      "Name Year_inducted Position Apps Goals\n",
      "\n",
      "Year 1st_Venue 2nd_Venue 3rd_Venue 4th_Venue 5th_Venue 6th_Venue\n",
      "\n",
      "Player Matches Innings Runs Average 100s 50s Games_Played Field_Goals Free_Throws Points\n",
      "\n",
      "Team County Wins Years_won Areas Prices\n",
      "\n",
      "Country Masters U.S._Open The_Open PGA Total\n",
      "\n",
      "Swara Position Short_name Notation Mnemonic\n",
      "\n",
      "State No._of_candidates No._of_elected Total_no._of_seats_in_Assembly Year_of_Election\n",
      "\n",
      "Discipline Amanda Bernie Javine_H Julia Michelle\n",
      "\n",
      "Nation Name Position League_Apps League_Goals FA_Cup_Apps FA_Cup_Goals Total_Apps Total_Goals\n",
      "\n",
      "Menteri_Besar Took_office Left_office Party\n",
      "\n"
     ]
    }
   ],
   "source": [
    "schema_collect = []\n",
    "with open('./rand.fi') as f_fi:\n",
    "    for line in f_fi:\n",
    "        if line in schema_collect:\n",
    "            continue\n",
    "        schema_collect.append(line)\n",
    "    \n",
    "for schema in schema_collect:\n",
    "    print schema"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2 Data Preparation and Generation\n",
    "\n",
    "### Next we do some data generation, the first goal is to double our current data size (8k~10k) \n",
    "\n",
    "As we previously did some work in the file ./data_prep/categorization.txt, we have several different sentences for a single length category. For each sentence structure, we first see whether it could applied to all or several schema, or just a single schema; then we tag each sentence, and for 'field' and 'value', we do data recombination for both query and logical forms; finally we add noise and replace synonyms in the queries to further complicate the sentence structrue.\n",
    "\n",
    "Let's start with the easiest length = 4:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os,sys,inspect\n",
    "\n",
    "import tagger as tg\n",
    "import tag_utils as tu\n",
    "from nltk.parse import stanford\n",
    "from nltk import tree\n",
    "\n",
    "currentdir = os.path.dirname(os.path.abspath(inspect.getfile(inspect.currentframe())))\n",
    "parentdir = os.path.dirname(currentdir)\n",
    "sys.path.insert(0,parentdir)\n",
    "os.environ['STANFORD_PARSER'] = '/Users/richard_xiong/Documents/DeepLearningMaster/deep_parser'\n",
    "os.environ['STANFORD_MODELS'] = '/Users/richard_xiong/Documents/DeepLearningMaster/deep_parser'\n",
    "\n",
    "parser = stanford.StanfordParser(model_path='/Users/richard_xiong/Documents/DeepLearningMaster/deep_parser/englishPCFG.ser.gz')\n",
    "\n",
    "#parsequery = \"which nation has less than 6 <field:1> but its <field:2> medals are more than 14 \"\n",
    "#parsequery = \"when the <field:1> was beijing and <field:2> was dubai , which city was the most recent <field:4>\"\n",
    "#parsequery = \"for <field:0> with more than 400 <field:1> and <field:2> less than 14 , <field:0> has the most <field:3>\"\n",
    "# parsequery = \"which state had the largest <field:1>, and its <field:2> are within 12 and 15\"\n",
    "# dependency_tree = parser.raw_parse_sents(('Hello, My name is Melroy', parsequery))\n",
    "\n",
    "# for line in dependency_tree[1]:\n",
    "#     line.draw()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to find which value corresponds to which field, we need to first find:\n",
    "1. the lowest common ancestor for each (value, field) pairs\n",
    "2. for each value, all different ancestors are belong to different levels, the deepest one, which should be the subtree for all the others, would contain the correspondence pair\n",
    "\n",
    "Possible functions:\n",
    "\n",
    "leaf_treeposition(self, index) ---> return: The tree position of the ``index``-th leaf in this\n",
    "            tree.  I.e., if ``tp=self.leaf_treeposition(i)``, then\n",
    "            ``self[tp]==self.leaves()[i]``.\n",
    "\n",
    "treeposition_spanning_leaves(self, start, end) ---> The tree position of the lowest descendant of this\n",
    "            tree that dominates ``self.leaves()[start:end]``.\n",
    "\n",
    "convert(cls, tree) ---> to subtype of Tree, say, ParentTree\n",
    "\n",
    "e.g.\n",
    "(0, 0, 1, 0, 0, 1, 0)\n",
    "(0, 0, 1, 0, 1, 1, 0, 0)\n",
    "(0, 0, 1, 2, 0, 0, 0)\n",
    "(0, 0, 1, 2, 1, 1, 0, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nation Rank Gold Silver Bronze Total\n",
      "\n",
      "Name Year_inducted Position Apps Goals\n",
      "\n",
      "State Year_of_Election No._of_candidates No._of_elected Total_no._of_seats_in_Assembly \n",
      "\n",
      "Team Years_won County Wins Areas Prices \n",
      "\n",
      "Player Matches Innings Runs Average 100s 50s Games_Played Field_Goals Free_Throws Points \n",
      "\n",
      "Country Masters U.S._Open The_Open PGA Total\n",
      "\n",
      "Discipline Amanda Bernie Javine_H Julia Michelle \n",
      "\n",
      "Nation Name Position League_Apps League_Goals FA_Cup_Apps FA_Cup_Goals Total_Apps Total_Goals \n",
      "\n",
      "Swara Position Short_name Notation Mnemonic \n",
      "\n",
      "Year 1st_Venue 2nd_Venue 3rd_Venue 4th_Venue 5th_Venue 6th_Venue \n",
      "\n",
      "Menteri_Besar Took_office Left_office Party\n",
      "\n"
     ]
    }
   ],
   "source": [
    "schema_collect[2] = \"State Year_of_Election No._of_candidates No._of_elected Total_no._of_seats_in_Assembly \\n\"\n",
    "schema_collect[7] = \"Year 1st_Venue 2nd_Venue 3rd_Venue 4th_Venue 5th_Venue 6th_Venue \\n\"\n",
    "schema_collect[3] = \"Team Years_won County Wins Areas Prices \\n\"\n",
    "schema_collect[4] = \"Player Matches Innings Runs Average 100s 50s Games_Played Field_Goals Free_Throws Points \\n\"\n",
    "\n",
    "schema_collect[6] = \"Discipline Amanda Bernie Javine_H Julia Michelle \\n\"\n",
    "schema_collect[8] = \"Swara Position Short_name Notation Mnemonic \\n\"\n",
    "schema_collect[7] = \"Nation Name Position League_Apps League_Goals FA_Cup_Apps FA_Cup_Goals Total_Apps Total_Goals \\n\"\n",
    "schema_collect[9] = \"Year 1st_Venue 2nd_Venue 3rd_Venue 4th_Venue 5th_Venue 6th_Venue \\n\"\n",
    "\n",
    "for schema in schema_collect:\n",
    "    print schema"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conventions \n",
    "1. \"o\" stands for \"ordinal\" values, refering to schema_collect[0:4]\n",
    "2. \"n\" stands for \"numerical\" values, refering to schema_collect[4:8]\n",
    "3. \"s\" stands for \"string\" values, refering to schema_collect[7:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Country Masters U.S._Open The_Open PGA Total\n",
      "what are the number of pga winning golfers that zimbabwe has\n",
      "['<field>', 'PGA']\n",
      "[(5, 0)]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "PGA\n",
      "<nan>\n",
      "what are the number of <field>:0 winning golfers that zimbabwe has\n",
      "select <field>:0 where <field>:1 equal <value>:1\n"
     ]
    }
   ],
   "source": [
    "collect4max = \"\"\"which country has the most pga\n",
    "which country has the most pga championships\n",
    "which country had the most number of wins\n",
    "which country won the largest haul of bronze medals\n",
    "who was the last de player\n",
    "which nation received the largest amount of gold medals\n",
    "the team with the most gold medals\n",
    "which nation was ranked last\n",
    "the country that won the most medals was\n",
    "what is the largest matches amount\"\"\".split('\\n')\n",
    "\n",
    "collect4min = \"\"\"who was the first nation\n",
    "what is the name of the first nation on this chart\n",
    "what is the name of the swara that holds the first position\n",
    "which country had the least bronze medals\n",
    "who scored the least on whitewater_kayak\n",
    "which state has the top no._of_elected amount\n",
    "who was the top scorer in innings\n",
    "what is the top listed player\n",
    "who is the top ranked nation\"\"\".split('\\n')\n",
    "\n",
    "collect6select = \"\"\"what are the number of league_apps ted_davis has\n",
    "what is the name of the only nation that did not earn any bronze medals\n",
    "what are the number of pga winning golfers that zimbabwe has\n",
    "who only won 13 silver medals\n",
    "which country was awarded more than 5 silver medals\n",
    "what is the number of wins for maynooth\n",
    "what was the number of silver medals the ivory_coast won\n",
    "only team to have more than 30 medals\n",
    "how many u.s._open wins does fiji have\n",
    "which country won only one medal, a bronze medal\n",
    "which ranking is mexico\n",
    "who won more gold medals than the united_states\n",
    "name a player whose average was above 25\n",
    "how many silver medals did brazil received\n",
    "name a player that play in no more than 13 innings\n",
    "what country has won no silver medals\n",
    "before 1990, how many pga were obtained\n",
    "what's the number of silver medals did chile win\"\"\".split('\\n')\n",
    "\n",
    "# How to deal with no/not which indicates zero?\n",
    "# The currect augmentation directly copy field name, could extend to query words\n",
    "# even the field not shown in the query, the current algorithm still works\n",
    "\n",
    "# print collect6select\n",
    "# print collect4max\n",
    "\n",
    "lo4max = 'select <field>:0 argmax <field>:1'\n",
    "lo4min = 'select <field>:0 argmin <field>:1'\n",
    "lo6select = 'select <field>:0 where <field>:1 equal <value>:1'\n",
    "\n",
    "print schema_collect[5], collect6select[2]\n",
    "tagged2, field_corr, value_corr, quTemp, _ = \\\n",
    "            tg.sentTagging_tree(parser, collect6select[2], schema_collect[5])\n",
    "print field_corr\n",
    "print value_corr \n",
    "print quTemp\n",
    "print lo6select"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Note:\n",
    "Each sentence could then be turned into a query tempelate after tagging. Now we have the logical template, query template, and several available schema (annotated by 'o' 'n' 's'), so combined with the field_corr and value_corr files we should be able to generate multiple sentences according to several schema."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['County', 'Prices'], ['Team', 'Prices'], ['County', 'Wins'], ['Team', 'Wins'], ['County', 'Areas'], ['Team', 'Areas']]\n"
     ]
    }
   ],
   "source": [
    "field_corr_dicts = [{'County': ['Louth', 'Dublin', 'Kildare', 'Laois', 'Wicklow'], 'Team': ['Ireland', 'Spain', 'Cyprus', 'Mexico', 'Maynooth']}, \\\n",
    "                    {'Prices': [28, 62, 72, 9, 40], 'Wins': [52, 80, 42, 76, 29], 'Areas': [38, 1, 7, 83, 98]}]\n",
    "\n",
    "def isRepetitive(sequence):\n",
    "    for element in sequence[:-1]:\n",
    "        if element == sequence[-1]:\n",
    "            return True\n",
    "    return False\n",
    "\n",
    "def generateFieldCombs(field_corr_dicts):\n",
    "    ''' If only fields are recombinable'''\n",
    "    list_of_seqs = []\n",
    "    if len(field_corr_dicts) == 1:\n",
    "        # base case:\n",
    "        for key in field_corr_dicts[0].keys():\n",
    "            list_of_seqs.append([key])\n",
    "    else:\n",
    "        # recursive case:\n",
    "        former_seqs = generateFieldCombs(field_corr_dicts[:-1])\n",
    "        for key in field_corr_dicts[-1].keys():\n",
    "            for seq in former_seqs:\n",
    "                newseq = [x for x in seq]\n",
    "                newseq.append(key)\n",
    "                # check new repetitive elements\n",
    "                if not isRepetitive(newseq):\n",
    "                    list_of_seqs.append(newseq)\n",
    "    return list_of_seqs\n",
    "\n",
    "def generateValueCombs(field_corr_dicts, field_combination, qu_value):\n",
    "    ''' Both fields and values are recombinable\n",
    "        arguments --- field_combination: the selected field combination, where the value are to be decided\n",
    "    '''\n",
    "    list_of_seqs = []\n",
    "    if len(qu_value) == 1:\n",
    "        # base case:\n",
    "        _, idx = qu_value[0]  # check position of values\n",
    "        for value in field_corr_dicts[idx][field_combination[idx]]:\n",
    "            list_of_seqs.append([value])\n",
    "    else:\n",
    "        # recursive case:\n",
    "        former_seqs = generateValueCombs(field_corr_dicts, field_combination, qu_value[:-1])\n",
    "        _, idx = qu_value[-1]\n",
    "        for value in field_corr_dicts[idx][field_combination[idx]]:\n",
    "            for seq in former_seqs:\n",
    "                newseq = [x for x in seq]\n",
    "                newseq.append(value)\n",
    "                # check new repetitive elements\n",
    "                if not isRepetitive(newseq):\n",
    "                    list_of_seqs.append(newseq)\n",
    "    return list_of_seqs\n",
    "\n",
    "print generateFieldCombs(field_corr_dicts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def schemaRecommend(field_corr_old, special_code):\n",
    "    ''' From the old generated field correspondence (string), transform to a new field correspondence, \n",
    "        represented by a list value_types, and from the set of value types to get the possible schemas \n",
    "        (PLURALS) that could use for augmentation later (check that all the types in field_corr_new \n",
    "        should be in each schema)\n",
    "        arguments --- special_code: might be used to indicate that the schema is not tranferrable. \n",
    "                      default False, means able to generalize to schema that contain corresponding field \n",
    "                      types; if True, means only applicable to original schema.\n",
    "        return --- field_corr: a list of value_types\n",
    "                   schemas: several schema that the template could augment to, each contain all the\n",
    "                   value_types needed; also see 'special_code'.\n",
    "    '''\n",
    "    return field_corr_new, schemas\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['<field>', '0']\n",
      "['<field>', '1']\n",
      "[(1, 0), (5, 1)] []\n",
      "['<field>', '0']\n",
      "['<field>', '1']\n",
      "[(1, 0), (3, 1)] []\n",
      "=== 0 schema ===\n",
      "[{'Nation': ['Greece', 'Thailand', 'Iran', 'Qatar', 'Soviet_Union']}, {'Bronze': [28, 19, 80, 67, 13], 'Silver': [76, 82, 88, 12, 24], 'Gold': [89, 30, 64, 96, 65]}]\n",
      "=== 1 schema ===\n",
      "[{'Position': ['Defender', 'Forward', 'CB', 'Goalkeeper', 'TE'], 'Name': ['Sandy_Mutch', 'Tony_Coton', 'Harry_Brough', 'Ian_Bolton', 'Stan_Pearson']}, {'Apps': [52, 46, 84, 25, 11], 'Goals': [92, 92, 90, 92, 56]}]\n",
      "=== 2 schema ===\n",
      "[{'State': ['Puducherry', 'Louisiana', 'Goa', 'Assam', 'Himachal_Pradesh']}, {'Total_no._of_seats_in_Assembly': [25, 81, 17, 98, 73], 'No._of_candidates': [5, 53, 73, 94, 75], 'No._of_elected': [1, 18, 56, 73, 84]}]\n",
      "=== 3 schema ===\n",
      "[{'County': ['Laois', 'Wicklow', 'Louth', 'Kildare', 'Dublin'], 'Team': ['Czech', 'Morocco', 'Mexico', 'Great_Britain', 'Scotland']}, {'Prices': [82, 67, 28, 6, 44], 'Wins': [26, 38, 9, 75, 92], 'Areas': [74, 22, 46, 5, 8]}]\n",
      "=== 4 schema ===\n",
      "[{'Player': ['Ted_Tyler', 'George_Nichols', 'Crescens_Robinson', 'Ernest_McKay', 'John_Felmley']}, {'Innings': [60, 9, 80, 5, 66], 'Runs': [93, 95, 66, 93, 84], 'Matches': [48, 17, 57, 38, 35], 'Field_Goals': [56, 85, 49, 95, 80], 'Free_Throws': [2, 64, 23, 83, 87], 'Points': [30, 42, 31, 12, 60], 'Games_Played': [14, 46, 73, 81, 44], '100s': [79, 42, 79, 16, 42], '50s': [68, 42, 54, 26, 73]}]\n",
      "=== 5 schema ===\n",
      "[{'Country': ['Switzerland', 'Uzbekistan', 'Ireland', 'Sweden', 'US']}, {'U.S._Open': [40, 4, 3, 22, 7], 'Masters': [59, 52, 39, 73, 25], 'The_Open': [1, 51, 54, 3, 41], 'PGA': [29, 40, 45, 33, 16]}]\n",
      "=== 6 schema ===\n",
      "[{'Discipline': ['Archery', 'Hurdles', 'Hammer', 'Whitewater_Kayak', 'Curling']}, {'Michelle': [84, 71, 17, 57, 29], 'Amanda': [25, 40, 56, 11, 63], 'Julia': [61, 44, 59, 46, 90], 'Javine_H': [99, 46, 48, 10, 82], 'Bernie': [47, 52, 46, 25, 81]}]\n",
      "=== 7 schema ===\n",
      "[{'Position': ['Goalkeeper', 'DE', 'S', 'QB', 'Midfielder'], 'Name': ['Ned_Barkas', 'Luther_Blissett', 'George_Brown', 'Ernie_Islip', 'Billy_Johnston'], 'Nation': ['Iraq', 'US', 'Uzbekistan', 'Vietnam', 'Jamaica']}, {'Total_Apps': [72, 48, 2, 97, 83], 'FA_Cup_Apps': [88, 41, 14, 15, 21], 'Total_Goals': [19, 12, 23, 77, 52], 'FA_Cup_Goals': [40, 58, 96, 13, 10], 'League_Apps': [4, 37, 38, 55, 50], 'League_Goals': [69, 9, 4, 53, 93]}]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(['which team has the most bronze',\n",
       "  'which nations has the most silver',\n",
       "  'which team has the most gold',\n",
       "  'which position has the most appearance',\n",
       "  'which name has the most appearances',\n",
       "  'which position has the most goals',\n",
       "  'which name has the most goal',\n",
       "  'which state has the most seat',\n",
       "  'which county has the most candidate',\n",
       "  'which county has the most no._of_elected',\n",
       "  'which county has the most price',\n",
       "  'which team has the most prices',\n",
       "  'which counties has the most wins',\n",
       "  'which team has the most wins',\n",
       "  'which county has the most area',\n",
       "  'which nation has the most area',\n",
       "  'which player has the most innings',\n",
       "  'which player has the most runs',\n",
       "  'which player has the most match',\n",
       "  'which player has the most goals',\n",
       "  'which player has the most free',\n",
       "  'which player has the most points',\n",
       "  'which player has the most games_played',\n",
       "  'which player has the most 100s',\n",
       "  'which player has the most 50s',\n",
       "  'which nations has the most u.s._open',\n",
       "  'which nations has the most masters',\n",
       "  'which team has the most the_open',\n",
       "  'which team has the most pga',\n",
       "  'which discipline has the most michelle',\n",
       "  'which discipline has the most amanda',\n",
       "  'which discipline has the most julia',\n",
       "  'which discipline has the most javine_h',\n",
       "  'which discipline has the most bernie',\n",
       "  'which position has the most appearances',\n",
       "  'which name has the most appearances',\n",
       "  'which country has the most appearances',\n",
       "  'which position has the most appearance',\n",
       "  'which name has the most appearance',\n",
       "  'which country has the most appearances',\n",
       "  'which position has the most goal',\n",
       "  'which name has the most goal',\n",
       "  'which nation has the most goal',\n",
       "  'which position has the most goal',\n",
       "  'which name has the most goal',\n",
       "  'which nation has the most goals',\n",
       "  'which position has the most appearance',\n",
       "  'which name has the most appearance',\n",
       "  'which nation has the most appearance',\n",
       "  'which position has the most goals',\n",
       "  'which name has the most goal',\n",
       "  'which country has the most goals'],\n",
       " ['select Nation argmax Bronze',\n",
       "  'select Nation argmax Silver',\n",
       "  'select Nation argmax Gold',\n",
       "  'select Position argmax Apps',\n",
       "  'select Name argmax Apps',\n",
       "  'select Position argmax Goals',\n",
       "  'select Name argmax Goals',\n",
       "  'select State argmax Total_no._of_seats_in_Assembly',\n",
       "  'select State argmax No._of_candidates',\n",
       "  'select State argmax No._of_elected',\n",
       "  'select County argmax Prices',\n",
       "  'select Team argmax Prices',\n",
       "  'select County argmax Wins',\n",
       "  'select Team argmax Wins',\n",
       "  'select County argmax Areas',\n",
       "  'select Team argmax Areas',\n",
       "  'select Player argmax Innings',\n",
       "  'select Player argmax Runs',\n",
       "  'select Player argmax Matches',\n",
       "  'select Player argmax Field_Goals',\n",
       "  'select Player argmax Free_Throws',\n",
       "  'select Player argmax Points',\n",
       "  'select Player argmax Games_Played',\n",
       "  'select Player argmax 100s',\n",
       "  'select Player argmax 50s',\n",
       "  'select Country argmax U.S._Open',\n",
       "  'select Country argmax Masters',\n",
       "  'select Country argmax The_Open',\n",
       "  'select Country argmax PGA',\n",
       "  'select Discipline argmax Michelle',\n",
       "  'select Discipline argmax Amanda',\n",
       "  'select Discipline argmax Julia',\n",
       "  'select Discipline argmax Javine_H',\n",
       "  'select Discipline argmax Bernie',\n",
       "  'select Position argmax Total_Apps',\n",
       "  'select Name argmax Total_Apps',\n",
       "  'select Nation argmax Total_Apps',\n",
       "  'select Position argmax FA_Cup_Apps',\n",
       "  'select Name argmax FA_Cup_Apps',\n",
       "  'select Nation argmax FA_Cup_Apps',\n",
       "  'select Position argmax Total_Goals',\n",
       "  'select Name argmax Total_Goals',\n",
       "  'select Nation argmax Total_Goals',\n",
       "  'select Position argmax FA_Cup_Goals',\n",
       "  'select Name argmax FA_Cup_Goals',\n",
       "  'select Nation argmax FA_Cup_Goals',\n",
       "  'select Position argmax League_Apps',\n",
       "  'select Name argmax League_Apps',\n",
       "  'select Nation argmax League_Apps',\n",
       "  'select Position argmax League_Goals',\n",
       "  'select Name argmax League_Goals',\n",
       "  'select Nation argmax League_Goals'],\n",
       " ['Nation Rank Gold Silver Bronze Total\\n',\n",
       "  'Nation Rank Gold Silver Bronze Total\\n',\n",
       "  'Nation Rank Gold Silver Bronze Total\\n',\n",
       "  'Name Year_inducted Position Apps Goals\\n',\n",
       "  'Name Year_inducted Position Apps Goals\\n',\n",
       "  'Name Year_inducted Position Apps Goals\\n',\n",
       "  'Name Year_inducted Position Apps Goals\\n',\n",
       "  'State Year_of_Election No._of_candidates No._of_elected Total_no._of_seats_in_Assembly \\n',\n",
       "  'State Year_of_Election No._of_candidates No._of_elected Total_no._of_seats_in_Assembly \\n',\n",
       "  'State Year_of_Election No._of_candidates No._of_elected Total_no._of_seats_in_Assembly \\n',\n",
       "  'Team Years_won County Wins Areas Prices \\n',\n",
       "  'Team Years_won County Wins Areas Prices \\n',\n",
       "  'Team Years_won County Wins Areas Prices \\n',\n",
       "  'Team Years_won County Wins Areas Prices \\n',\n",
       "  'Team Years_won County Wins Areas Prices \\n',\n",
       "  'Team Years_won County Wins Areas Prices \\n',\n",
       "  'Player Matches Innings Runs Average 100s 50s Games_Played Field_Goals Free_Throws Points \\n',\n",
       "  'Player Matches Innings Runs Average 100s 50s Games_Played Field_Goals Free_Throws Points \\n',\n",
       "  'Player Matches Innings Runs Average 100s 50s Games_Played Field_Goals Free_Throws Points \\n',\n",
       "  'Player Matches Innings Runs Average 100s 50s Games_Played Field_Goals Free_Throws Points \\n',\n",
       "  'Player Matches Innings Runs Average 100s 50s Games_Played Field_Goals Free_Throws Points \\n',\n",
       "  'Player Matches Innings Runs Average 100s 50s Games_Played Field_Goals Free_Throws Points \\n',\n",
       "  'Player Matches Innings Runs Average 100s 50s Games_Played Field_Goals Free_Throws Points \\n',\n",
       "  'Player Matches Innings Runs Average 100s 50s Games_Played Field_Goals Free_Throws Points \\n',\n",
       "  'Player Matches Innings Runs Average 100s 50s Games_Played Field_Goals Free_Throws Points \\n',\n",
       "  'Country Masters U.S._Open The_Open PGA Total\\n',\n",
       "  'Country Masters U.S._Open The_Open PGA Total\\n',\n",
       "  'Country Masters U.S._Open The_Open PGA Total\\n',\n",
       "  'Country Masters U.S._Open The_Open PGA Total\\n',\n",
       "  'Discipline Amanda Bernie Javine_H Julia Michelle \\n',\n",
       "  'Discipline Amanda Bernie Javine_H Julia Michelle \\n',\n",
       "  'Discipline Amanda Bernie Javine_H Julia Michelle \\n',\n",
       "  'Discipline Amanda Bernie Javine_H Julia Michelle \\n',\n",
       "  'Discipline Amanda Bernie Javine_H Julia Michelle \\n',\n",
       "  'Nation Name Position League_Apps League_Goals FA_Cup_Apps FA_Cup_Goals Total_Apps Total_Goals \\n',\n",
       "  'Nation Name Position League_Apps League_Goals FA_Cup_Apps FA_Cup_Goals Total_Apps Total_Goals \\n',\n",
       "  'Nation Name Position League_Apps League_Goals FA_Cup_Apps FA_Cup_Goals Total_Apps Total_Goals \\n',\n",
       "  'Nation Name Position League_Apps League_Goals FA_Cup_Apps FA_Cup_Goals Total_Apps Total_Goals \\n',\n",
       "  'Nation Name Position League_Apps League_Goals FA_Cup_Apps FA_Cup_Goals Total_Apps Total_Goals \\n',\n",
       "  'Nation Name Position League_Apps League_Goals FA_Cup_Apps FA_Cup_Goals Total_Apps Total_Goals \\n',\n",
       "  'Nation Name Position League_Apps League_Goals FA_Cup_Apps FA_Cup_Goals Total_Apps Total_Goals \\n',\n",
       "  'Nation Name Position League_Apps League_Goals FA_Cup_Apps FA_Cup_Goals Total_Apps Total_Goals \\n',\n",
       "  'Nation Name Position League_Apps League_Goals FA_Cup_Apps FA_Cup_Goals Total_Apps Total_Goals \\n',\n",
       "  'Nation Name Position League_Apps League_Goals FA_Cup_Apps FA_Cup_Goals Total_Apps Total_Goals \\n',\n",
       "  'Nation Name Position League_Apps League_Goals FA_Cup_Apps FA_Cup_Goals Total_Apps Total_Goals \\n',\n",
       "  'Nation Name Position League_Apps League_Goals FA_Cup_Apps FA_Cup_Goals Total_Apps Total_Goals \\n',\n",
       "  'Nation Name Position League_Apps League_Goals FA_Cup_Apps FA_Cup_Goals Total_Apps Total_Goals \\n',\n",
       "  'Nation Name Position League_Apps League_Goals FA_Cup_Apps FA_Cup_Goals Total_Apps Total_Goals \\n',\n",
       "  'Nation Name Position League_Apps League_Goals FA_Cup_Apps FA_Cup_Goals Total_Apps Total_Goals \\n',\n",
       "  'Nation Name Position League_Apps League_Goals FA_Cup_Apps FA_Cup_Goals Total_Apps Total_Goals \\n',\n",
       "  'Nation Name Position League_Apps League_Goals FA_Cup_Apps FA_Cup_Goals Total_Apps Total_Goals \\n',\n",
       "  'Nation Name Position League_Apps League_Goals FA_Cup_Apps FA_Cup_Goals Total_Apps Total_Goals \\n'])"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "field_corr_new = ['string', 'int']\n",
    "schema_aug = schema_collect[0:8]\n",
    "\n",
    "def augment4max(quTemp, loTemp, field_corr, schema_aug):\n",
    "    ''' Data augmentation from a pair of query template and logical template\n",
    "        arguments --- field_corr: a list of value_types e.g. ['string','ordinal','int'], each idx should \n",
    "                      correspond to the postion in the templates\n",
    "                      schemas: PLURALS HERE! several schemas that the template could augment to.\n",
    "        return --- collections of queries, logics, and fields\n",
    "    '''\n",
    "    queryCollect, logicCollect, fieldCollect = [], [], []\n",
    "    config = tu.Config()\n",
    "    \n",
    "    # Step 1: preparation\n",
    "    query = quTemp.split()\n",
    "    logic = loTemp.split()\n",
    "    qu_field = []  # positions of field in query\n",
    "    qu_value = []  # positions of value in query\n",
    "    lo_field = []  # positions of field in logic\n",
    "    lo_value = []  # positions of value in logic\n",
    "    for i in range(len(query)):\n",
    "        reference = query[i].split(':')\n",
    "        if len(reference) == 1:\n",
    "            continue\n",
    "        print reference\n",
    "        idx = int(reference[1])\n",
    "        if reference[0] == '<field>':\n",
    "            qu_field.append((i, idx))\n",
    "        else:\n",
    "            qu_value.append((i, idx))\n",
    "    print qu_field, qu_value\n",
    "    for i in range(len(logic)):\n",
    "        reference = logic[i].split(':')\n",
    "        if len(reference) == 1:\n",
    "            continue\n",
    "        print reference\n",
    "        idx = int(reference[1])\n",
    "        if reference[0] == '<field>':\n",
    "            lo_field.append((i, idx))\n",
    "        else:\n",
    "            lo_value.append((i, idx))\n",
    "    print lo_field, lo_value\n",
    "    \n",
    "    # Step 2: augment to different schemas\n",
    "    for j in range(len(schema_aug)):\n",
    "        # Step 2.1: for each schema, build correspondence list of dictionarys: [{}, {}, {}]\n",
    "        field_corr_dicts = []\n",
    "        print '=== %d schema ===' %j\n",
    "        schema = schema_aug[j].split()\n",
    "        #print schema\n",
    "        # because there could be multiple same-type fields in one sentences, we go over field_corr\n",
    "        for k in range(len(field_corr)):\n",
    "            field_corr_dict = dict()\n",
    "            for i in range(len(schema)):\n",
    "                field = schema[i]\n",
    "                #print field\n",
    "                if schema[i] == 'Total' or schema[i] == 'Average':\n",
    "                    continue\n",
    "                value_type = config.field2word[schema[i]]['value_type']\n",
    "                #print value_type\n",
    "                if value_type == field_corr[k]:\n",
    "                    if value_type == 'string':\n",
    "                        #field_corr_dict[field] = config.field2word[schema[i]]['value_range']\n",
    "                        field_corr_dict[field] = random.sample(config.field2word[schema[i]]['value_range'], 5)\n",
    "                    elif value_type == 'int':\n",
    "                        field_corr_dict[field] = [random.randint(1, 99) for i in range(5)]\n",
    "                    elif value_type == 'date':\n",
    "                        field_corr_dict[field] = [random.randint(1970, 2010) for i in range(5)]\n",
    "                    elif value_type == 'ordinal':\n",
    "                        field_corr_dict[field] = [random.randint(1, 9) for i in range(3)]\n",
    "            field_corr_dicts.append(field_corr_dict)\n",
    "        print field_corr_dicts \n",
    "        # now the list of dicts [{str_field1:[], str_field2:[], ...}, {int_field1:[], int_field2:[], ...}]\n",
    "        \n",
    "        # Step 2.2: Regenerate sentence by filling into the place\n",
    "        field_combinations = generateFieldCombs(field_corr_dicts)\n",
    "        for combination in field_combinations:\n",
    "            newquery = [x for x in query]\n",
    "            newlogic = [x for x in logic]\n",
    "            # regenerate query, lower case or query_word\n",
    "            for (posit, idx) in qu_field:\n",
    "                field_info = config.field2word[combination[idx]]\n",
    "                if len(field_info['query_word']) > 1:\n",
    "                    pick = random.choice(field_info['query_word'])\n",
    "                    while pick == 'who' or pick == 'when' or pick == 'city':\n",
    "                        pick = random.choice(field_info['query_word'])\n",
    "                    newquery[posit] = pick\n",
    "                else:\n",
    "                    newquery[posit] = combination[idx].lower()                \n",
    "            # regenerate logic forms\n",
    "            for (posit, idx) in lo_field:\n",
    "                newlogic[posit] = combination[idx]\n",
    "            queryCollect.append(' '.join(newquery))\n",
    "            logicCollect.append(' '.join(newlogic))\n",
    "            fieldCollect.append(schema_aug[j])\n",
    "    return queryCollect, logicCollect, fieldCollect, \n",
    "\n",
    "augment4max(quTemp, lo4max, field_corr_new, schema_aug)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['nation']\n"
     ]
    }
   ],
   "source": [
    "key = 'nation'\n",
    "turn = [key]\n",
    "print turn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
