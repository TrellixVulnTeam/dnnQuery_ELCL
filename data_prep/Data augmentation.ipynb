{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data augmentation\n",
    "\n",
    "## 1 Current data statistics\n",
    "\n",
    "### We read in the files: \n",
    "of queries, logical forms, and schema, and categorize them by length; within the same length, there would be subcategories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "length = 2, total examples: 2\n",
      "length = 4, total examples: 156\n",
      "length = 6, total examples: 1253\n",
      "length = 8, total examples: 624\n",
      "length = 10, total examples: 687\n",
      "length = 11, total examples: 697\n",
      "length = 12, total examples: 488\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "import math\n",
    "\n",
    "logic_category_len = dict()\n",
    "query_len = dict()\n",
    "schema_len = dict()\n",
    "with open('./rand.lo') as f_lo:\n",
    "    with open('./rand.qu') as f_qu:\n",
    "        with open('./rand.fi') as f_fi:\n",
    "            logic_line, query_line, schema_line = f_lo.readline(), f_qu.readline(), f_fi.readline()\n",
    "            while logic_line and query_line and schema_line:\n",
    "                logic = logic_line.split()\n",
    "#                 if len(logic) == 13:\n",
    "#                     if logic[4] == 'less':\n",
    "#                         logic[0] = 'argmax'\n",
    "#                     else:\n",
    "#                         logic[0] = 'argmin'\n",
    "#                     logic.insert(2, logic[3])\n",
    "                length = len(logic)\n",
    "#                 if length ==0:\n",
    "#                     continue\n",
    "                if length not in logic_category_len:\n",
    "                    logic_category_len[length] = []\n",
    "                    query_len[length] = []\n",
    "                    schema_len[length] = []\n",
    "                logic_category_len[length].append(logic_line)\n",
    "                query_len[length].append(query_line)\n",
    "                schema_len[length].append(schema_line)\n",
    "                logic_line, query_line, schema_line = f_lo.readline(), f_qu.readline(), f_fi.readline()\n",
    "for key in logic_category_len.keys():\n",
    "    value = logic_category_len[key]\n",
    "    print 'length = %d, total examples: %d' %(key, len(value))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Have a look at the data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "how many elected are there in total\n",
      "\n",
      "how many candidates are there in total\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(logic_category_len[2])):\n",
    "    #print i\n",
    "    print query_len[2][i]\n",
    "    #print logic_category_len[14][i]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now we collect all different schema in a list for later use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nation Rank Gold Silver Bronze Total\n",
      "\n",
      "Name Year_inducted Position Apps Goals\n",
      "\n",
      "State Year_of_Election No._of_candidates No._of_elected Total_no._of_seats_in_Assembly \n",
      "\n",
      "Team Years_won County Wins Areas Prices \n",
      "\n",
      "Player Matches Innings Runs Average 100s 50s Games_Played Field_Goals Free_Throws Points \n",
      "\n",
      "Country Masters U.S._Open The_Open PGA Total\n",
      "\n",
      "Discipline Amanda Bernie Javine_H Julia Michelle \n",
      "\n",
      "Nation Name Position League_Apps League_Goals FA_Cup_Apps FA_Cup_Goals Total_Apps Total_Goals \n",
      "\n",
      "Swara Position Short_name Notation Mnemonic \n",
      "\n",
      "Year 1st_Venue 2nd_Venue 3rd_Venue 4th_Venue 5th_Venue 6th_Venue \n",
      "\n",
      "Menteri_Besar Took_office Left_office Party\n",
      "\n"
     ]
    }
   ],
   "source": [
    "schema_collect = []\n",
    "with open('./rand.fi') as f_fi:\n",
    "    for line in f_fi:\n",
    "        if line in schema_collect:\n",
    "            continue\n",
    "        schema_collect.append(line)\n",
    "    \n",
    "schema_collect[2] = \"State Year_of_Election No._of_candidates No._of_elected Total_no._of_seats_in_Assembly \\n\"\n",
    "schema_collect[7] = \"Year 1st_Venue 2nd_Venue 3rd_Venue 4th_Venue 5th_Venue 6th_Venue \\n\"\n",
    "schema_collect[3] = \"Team Years_won County Wins Areas Prices \\n\"\n",
    "schema_collect[4] = \"Player Matches Innings Runs Average 100s 50s Games_Played Field_Goals Free_Throws Points \\n\"\n",
    "\n",
    "schema_collect[6] = \"Discipline Amanda Bernie Javine_H Julia Michelle \\n\"\n",
    "schema_collect[8] = \"Swara Position Short_name Notation Mnemonic \\n\"\n",
    "schema_collect[7] = \"Nation Name Position League_Apps League_Goals FA_Cup_Apps FA_Cup_Goals Total_Apps Total_Goals \\n\"\n",
    "schema_collect[9] = \"Year 1st_Venue 2nd_Venue 3rd_Venue 4th_Venue 5th_Venue 6th_Venue \\n\"\n",
    "\n",
    "for schema in schema_collect:\n",
    "    print schema"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2 Data Preparation and Generation\n",
    "\n",
    "### Next we do some data generation, the first goal is to double our current data size (8k~10k) \n",
    "\n",
    "As we previously did some work in the file ./data_prep/categorization.txt, we have several different sentences for a single length category. For each sentence structure, we first see whether it could applied to all or several schema, or just a single schema; then we tag each sentence, and for 'field' and 'value', we do data recombination for both query and logical forms; finally we add noise and replace synonyms in the queries to further complicate the sentence structrue.\n",
    "\n",
    "Let's start with the easiest length = 4:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Importing GloVe pretrained word vectors\n",
      "Replacing GloVe word vectors as initialization\n"
     ]
    }
   ],
   "source": [
    "import os,sys,inspect\n",
    "import random\n",
    "import numpy as np\n",
    "\n",
    "import tagger as tg\n",
    "import tag_utils as tu\n",
    "from nltk.parse import stanford\n",
    "from nltk import tree\n",
    "\n",
    "currentdir = os.path.dirname(os.path.abspath(inspect.getfile(inspect.currentframe())))\n",
    "parentdir = os.path.dirname(currentdir)\n",
    "sys.path.insert(0,parentdir)\n",
    "os.environ['STANFORD_PARSER'] = '/Users/richard_xiong/Documents/DeepLearningMaster/deep_parser'\n",
    "os.environ['STANFORD_MODELS'] = '/Users/richard_xiong/Documents/DeepLearningMaster/deep_parser'\n",
    "\n",
    "#parsequery = \"which nation has less than 6 <field:1> but its <field:2> medals are more than 14 \"\n",
    "#parsequery = \"when the <field:1> was beijing and <field:2> was dubai , which city was the most recent <field:4>\"\n",
    "#parsequery = \"for <field:0> with more than 400 <field:1> and <field:2> less than 14 , <field:0> has the most <field:3>\"\n",
    "# parsequery = \"which state had the largest <field:1>, and its <field:2> are within 12 and 15\"\n",
    "# dependency_tree = parser.raw_parse_sents(('Hello, My name is Melroy', parsequery))\n",
    "\n",
    "# for line in dependency_tree[1]:\n",
    "#     line.draw()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to find which value corresponds to which field, we need to first find:\n",
    "1. the lowest common ancestor for each (value, field) pairs\n",
    "2. for each value, all different ancestors are belong to different levels, the deepest one, which should be the subtree for all the others, would contain the correspondence pair\n",
    "\n",
    "Possible functions:\n",
    "\n",
    "leaf_treeposition(self, index) ---> return: The tree position of the ``index``-th leaf in this\n",
    "            tree.  I.e., if ``tp=self.leaf_treeposition(i)``, then\n",
    "            ``self[tp]==self.leaves()[i]``.\n",
    "\n",
    "treeposition_spanning_leaves(self, start, end) ---> The tree position of the lowest descendant of this\n",
    "            tree that dominates ``self.leaves()[start:end]``.\n",
    "\n",
    "convert(cls, tree) ---> to subtype of Tree, say, ParentTree\n",
    "\n",
    "e.g.\n",
    "(0, 0, 1, 0, 0, 1, 0)\n",
    "(0, 0, 1, 0, 1, 1, 0, 0)\n",
    "(0, 0, 1, 2, 0, 0, 0)\n",
    "(0, 0, 1, 2, 1, 1, 0, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#field_corr_dicts = [{'County': ['Louth', 'Dublin', 'Kildare', 'Laois', 'Wicklow'], 'Team': ['Ireland', 'Spain', 'Cyprus', 'Mexico', 'Maynooth']}, \\\n",
    "#                    {'Prices': [28, 62, 72, 9, 40], 'Wins': [52, 80, 42, 76, 29], 'Areas': [38, 1, 7, 83, 98]}]\n",
    "\n",
    "def isRepetitive(sequence):\n",
    "    for element in sequence[:-1]:\n",
    "        if element == sequence[-1]:\n",
    "            return True\n",
    "    return False\n",
    "\n",
    "def generateFieldCombs(field_corr_dicts):\n",
    "    ''' If only fields are recombinable'''\n",
    "    list_of_seqs = []\n",
    "    if len(field_corr_dicts) == 1:\n",
    "        # base case:\n",
    "        for key in field_corr_dicts[0].keys():\n",
    "            list_of_seqs.append([key])\n",
    "    else:\n",
    "        # recursive case:\n",
    "        former_seqs = generateFieldCombs(field_corr_dicts[:-1])\n",
    "        for key in field_corr_dicts[-1].keys():\n",
    "            for seq in former_seqs:\n",
    "                newseq = [x for x in seq]\n",
    "                newseq.append(key)\n",
    "                # check new repetitive elements\n",
    "                if not isRepetitive(newseq):\n",
    "                    list_of_seqs.append(newseq)\n",
    "    return list_of_seqs\n",
    "\n",
    "def generateValueCombs(field_corr_dicts, field_combination, qu_value):\n",
    "    ''' Both fields and values are recombinable\n",
    "        arguments --- field_combination: the selected field combination, where the value are to be decided\n",
    "    '''\n",
    "    list_of_seqs = []\n",
    "    if len(qu_value) == 1:\n",
    "        # base case:\n",
    "        _, idx = qu_value[0]  # check position of values\n",
    "        for value in field_corr_dicts[idx][field_combination[idx]]:\n",
    "            list_of_seqs.append([value])\n",
    "    else:\n",
    "        # recursive case:\n",
    "        former_seqs = generateValueCombs(field_corr_dicts, field_combination, qu_value[:-1])\n",
    "        _, idx = qu_value[-1]\n",
    "        for value in field_corr_dicts[idx][field_combination[idx]]:\n",
    "            for seq in former_seqs:\n",
    "                newseq = [x for x in seq]\n",
    "                newseq.append(value)\n",
    "                # check new repetitive elements\n",
    "                if not isRepetitive(newseq):\n",
    "                    list_of_seqs.append(newseq)\n",
    "    return list_of_seqs\n",
    "\n",
    "#print generateFieldCombs(field_corr_dicts)\n",
    "#print generateValueCombs(field_corr_dicts, ['County', 'Wins'], [(2,0), (4,1)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def isContainFieldType(schema_type, field_corr):\n",
    "    ''' To determine whether all the types in field_corr appear in the schema\n",
    "        e.g. field_corr = ['string', 'string', 'int'], an available schema should at least contain\n",
    "        two 'string type' and one 'int' type\n",
    "        arguments --- schema_type: a list of corresponding types of the schema\n",
    "                      field_corr: a list of field types appeared in the query\n",
    "        return --- True or False\n",
    "    '''\n",
    "    small_dict = dict() # for field_corr\n",
    "    big_dict = dict()   # for schema_type\n",
    "    # build dictionaries\n",
    "    for field in field_corr:\n",
    "        if field not in small_dict:\n",
    "            small_dict[field] = 0\n",
    "        small_dict[field] += 1\n",
    "    for field in schema_type:\n",
    "        if field not in big_dict:\n",
    "            big_dict[field] = 0\n",
    "        big_dict[field] += 1\n",
    "    for key in small_dict.keys():\n",
    "        if key not in big_dict:\n",
    "            return False\n",
    "        elif big_dict[key] < small_dict[key]:\n",
    "            return False\n",
    "    return True\n",
    "\n",
    "def schemaRecommend(schema_idx, field_corr_old, special_code=False):\n",
    "    ''' From the old generated field correspondence (string), transform to a new field correspondence, \n",
    "        represented by a list value_types, and from the set of value types to get the possible schemas \n",
    "        (PLURALS) that could use for augmentation later (check that all the types in field_corr_new \n",
    "        should be in each schema)\n",
    "        arguments --- schema_idx: the index number of the original query is based on  \n",
    "                      special_code: might be used to indicate that the schema is not tranferrable. \n",
    "                      default False, means able to generalize to schema that contain corresponding field \n",
    "                      types; if True, means only applicable to original schema.\n",
    "        return --- field_corr_new: a list of value_types\n",
    "                   schemas: several schema that the template could augment to, each contain all the\n",
    "                   value_types needed; also see 'special_code'.\n",
    "    '''\n",
    "    config = tu.Config()  # Contain the schema_collect and schema_collect_type information\n",
    "    field_corr_old = field_corr_old.split()\n",
    "    field_corr_new = ['' for x in field_corr_old]\n",
    "    for i in range(len(field_corr_old)):\n",
    "        field_type = config.field2word[field_corr_old[i]]['value_type']\n",
    "        field_corr_new[i] = field_type\n",
    "    \n",
    "    schemas = []\n",
    "    if special_code:\n",
    "        # only the original schema goes into the next stage\n",
    "        schemas.append(config.schema_collect[schema_idx])\n",
    "        return field_corr_new, schemas\n",
    "    \n",
    "    # length = len(config.schema_collect)\n",
    "    length = 9 # ONLY take the first 9 schema\n",
    "    for j in range(length):\n",
    "        # print '*** schema %d ***' %j\n",
    "        if isContainFieldType(config.schema_collect_type[j], field_corr_new):\n",
    "            schemas.append(config.schema_collect[j])\n",
    "    \n",
    "    return field_corr_new, schemas\n",
    "#schemaRecommend(5, 'PGA Country')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# field_corr_new, schema_aug = schemaRecommend(5, 'PGA Country')\n",
    "# field_corr_new = ['int','string']\n",
    "# schema_aug = main_config.schema_collect[0:8]\n",
    "\n",
    "def augment(quTemp, loTemp, field_corr, schema_aug):\n",
    "    ''' Data augmentation from a pair of query template and logical template\n",
    "        arguments --- field_corr: a list of value_types e.g. ['string','ordinal','int'], each idx should \n",
    "                      correspond to the postion in the templates\n",
    "                      schemas: PLURALS HERE! several schemas that the template could augment to.\n",
    "        return --- collections of queries, logics, and fields\n",
    "    '''\n",
    "    queryCollect, logicCollect, fieldCollect = [], [], []\n",
    "    config = tu.Config()\n",
    "    \n",
    "    # Step 1: preparation\n",
    "    query = quTemp.split()\n",
    "    logic = loTemp.split()\n",
    "    qu_field = []  # positions of field in query\n",
    "    qu_value = []  # positions of value in query\n",
    "    lo_field = []  # positions of field in logic\n",
    "    lo_value = []  # positions of value in logic\n",
    "    for i in range(len(query)):\n",
    "        reference = query[i].split(':')\n",
    "        if len(reference) == 1:\n",
    "            continue\n",
    "        print reference\n",
    "        idx = int(reference[1])\n",
    "        if reference[0] == '<field>':\n",
    "            qu_field.append((i, idx))\n",
    "        else:\n",
    "            qu_value.append((i, idx))\n",
    "    print qu_field, qu_value\n",
    "    for i in range(len(logic)):\n",
    "        reference = logic[i].split(':')\n",
    "        if len(reference) == 1:\n",
    "            continue\n",
    "        print reference\n",
    "        idx = int(reference[1])\n",
    "        if reference[0] == '<field>':\n",
    "            lo_field.append((i, idx))\n",
    "        else:\n",
    "            lo_value.append((i, idx))\n",
    "    print lo_field, lo_value\n",
    "    \n",
    "    # Step 2: augment to different schemas\n",
    "    for j in range(len(schema_aug)):\n",
    "        # Step 2.1: for each schema, build correspondence list of dictionarys: [{}, {}, {}]\n",
    "        field_corr_dicts = []\n",
    "        # print '=== %d schema ===' %j\n",
    "        schema = schema_aug[j]\n",
    "        # because there could be multiple same-type fields in one sentences, we go over field_corr\n",
    "        for k in range(len(field_corr)):\n",
    "            field_corr_dict = dict()\n",
    "            for i in range(len(schema)):\n",
    "                field = schema[i]\n",
    "                #print field\n",
    "                if schema[i] == 'Total' or schema[i] == 'Average':\n",
    "                    continue\n",
    "                value_type = config.field2word[schema[i]]['value_type']\n",
    "                if value_type == field_corr[k]:\n",
    "                    if value_type == 'string':\n",
    "                        #field_corr_dict[field] = config.field2word[schema[i]]['value_range']\n",
    "                        num_sample = 3\n",
    "                        if len(config.field2word[schema[i]]['value_range']) < num_sample:\n",
    "                            num_sample = len(config.field2word[schema[i]]['value_range'])\n",
    "                        field_corr_dict[field] = random.sample(config.field2word[schema[i]]['value_range'], num_sample)\n",
    "                    elif value_type == 'int':\n",
    "                        field_corr_dict[field] = random.sample(range(1, 100), 3) \n",
    "                    elif value_type == 'date':\n",
    "                        field_corr_dict[field] = random.sample(range(1970, 2011), 3)\n",
    "                    elif value_type == 'ordinal':\n",
    "                        field_corr_dict[field] = random.sample(['first', 'second', 'third', 'fourth', 'fifth', 'sixth','seventh', \\\n",
    "                                                                'eighth','ninth','last','1st', '2nd', '3rd', '4th', '5th',\\\n",
    "                                                                '6th','7th','8th','9th'], 3)\n",
    "            field_corr_dicts.append(field_corr_dict)\n",
    "        # print field_corr_dicts \n",
    "        # now the list of dicts [{str_field1:[], str_field2:[], ...}, {int_field1:[], int_field2:[], ...}]\n",
    "        \n",
    "        # Step 2.2: Regenerate sentence by filling into the place\n",
    "        field_combinations = generateFieldCombs(field_corr_dicts)\n",
    "        for field_combination in field_combinations:\n",
    "            print field_combination\n",
    "            newquery = [x for x in query]\n",
    "            newlogic = [x for x in logic]\n",
    "            # regenerate query, lower case or query_word\n",
    "            for (posit, idx) in qu_field:\n",
    "                field_info = config.field2word[field_combination[idx]]\n",
    "                if len(field_info['query_word']) > 1:\n",
    "                    if posit == 0 and 'who' in field_info['query_word']:\n",
    "                        pick = 'who'\n",
    "                    elif posit == 0 and 'when' in field_info['query_word']:\n",
    "                        pick = 'when'\n",
    "                    else:\n",
    "                        pick = random.choice(field_info['query_word'])\n",
    "                        while pick == 'who' or pick == 'when' or pick == 'city':\n",
    "                            pick = random.choice(field_info['query_word'])\n",
    "                    newquery[posit] = pick\n",
    "                else:\n",
    "                    newquery[posit] = field_combination[idx].lower()                \n",
    "            # regenerate logic forms\n",
    "            for (posit, idx) in lo_field:\n",
    "                newlogic[posit] = field_combination[idx]\n",
    "            if len(qu_value) > 0:\n",
    "                value_combinations = generateValueCombs(field_corr_dicts, field_combination, qu_value)\n",
    "                for value_combination in value_combinations:\n",
    "                    morequery = [x for x in newquery]\n",
    "                    morelogic = [x for x in newlogic]\n",
    "                    for i in range(len(qu_value)):\n",
    "                        morequery[qu_value[i][0]] = str(value_combination[i]).lower()\n",
    "                    for i in range(len(lo_value)):\n",
    "                        morelogic[lo_value[i][0]] = str(value_combination[i])\n",
    "                    queryCollect.append(' '.join(morequery))\n",
    "                    if isRepetitive(queryCollect):\n",
    "                        del queryCollect[-1]\n",
    "                        continue\n",
    "                    logicCollect.append(' '.join(morelogic))\n",
    "                    fieldCollect.append(' '.join(schema_aug[j]))\n",
    "                continue\n",
    "            queryCollect.append(' '.join(newquery))\n",
    "            if isRepetitive(queryCollect):\n",
    "                del queryCollect[-1]\n",
    "                continue\n",
    "            logicCollect.append(' '.join(newlogic))\n",
    "            fieldCollect.append(' '.join(schema_aug[j]))\n",
    "    return queryCollect, logicCollect, fieldCollect\n",
    "\n",
    "# augment(quTemp, lo6select, field_corr_new, schema_aug)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conventions \n",
    "Each sentence could then be turned into a query tempelate after tagging. Now we have the logical template, query template, and several available schema, so combined with the field_corr and value_corr files we should be able to generate multiple sentences according to several schema."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "collect2sum = \"\"\"\n",
    "how many elected are there in total;2\n",
    "what is the total number of gold earned;0;t\n",
    "the total of gold on the chart;0\n",
    "what is the total amount of gold combined;0\n",
    "what is the total gold on the chart;0\n",
    "the total gold in the table;0\n",
    "how many gold medals were there all together;0;t\n",
    "how many total gold medals were awarded;0;t\n",
    "how many gold were there all together;0\n",
    "what is the total if you add all of the bronze numbers together;0\n",
    "\"\"\".split('\\n')\n",
    "\n",
    "collect2avg = \"\"\"\n",
    "how many elected are there in average;2\n",
    "what is the average number of gold earned;0;t\n",
    "what is the average number of gold;0\n",
    "the average number of gold;0\n",
    "the average amount of gold earned;0;t\n",
    "what is the average score on innings;4;t\n",
    "what is the average of innings;4\n",
    "how many runs are assigned per player;4;t\n",
    "how many runs per player;4;t\n",
    "how many gold medals per country;0;t\n",
    "how many number_of_seat per state;2;t\n",
    "how many the_open winner per country;5;t\n",
    "the number of runs are assigned per player;4;t\n",
    "the number of runs per player;4;t\n",
    "the amount of gold medals per country;0;t\n",
    "amount of number_of_elected per state;2;t\n",
    "number of the_open winner per country;5;t\n",
    "\"\"\".split('\\n')\n",
    "\n",
    "collect4max = \"\"\"which country has the most pga;5\n",
    "which country has the most pga championships;5;t\n",
    "which country had the most number of wins;3\n",
    "which country won the largest haul of bronze medals;0;t\n",
    "which nation received the largest amount of gold medals;0;t\n",
    "the team with the most gold medals;0;t\n",
    "the team with the most gold;0\n",
    "which state has the top no._of_elected amount;2\n",
    "who was the top scorer in innings;4;t\n",
    "the country that won the most silver medals was;0;t\n",
    "which country had the most bronze medals;0;t\n",
    "which nation was ranked last;0;t\n",
    "who was the last nation;0;t\n",
    "\"\"\".split('\\n')\n",
    "\n",
    "collect4max_1 = \"\"\"\n",
    "who was the last player;4;t\n",
    "who was the last state;2;t\n",
    "what is the name of the last swara on this chart;7\n",
    "what is the swara that holds the last position;7\n",
    "what is the largest matches amount;4\n",
    "\"\"\".split('\\n')\n",
    "\n",
    "collect4min = \"\"\"which country had the least bronze medals;0;t\n",
    "which country had the least bronze;0\n",
    "which country has the least pga championships;5;t\n",
    "which country had the least number of wins;3\n",
    "which nation received the smallest amount of gold medals;0;t\n",
    "the team with the least gold medals;0;t\n",
    "the team with the least gold;0\n",
    "which nation was ranked first;0\n",
    "the country that won the least silver medals was;0;t\n",
    "who is the top ranked nation;0;t\n",
    "who was the first nation;0;t\n",
    "\"\"\".split('\\n')\n",
    "\n",
    "collect4min_1 = \"\"\"\n",
    "who was the first player;4;t\n",
    "who was the first state;2;t\n",
    "what is the name of the first swara on this chart;7\n",
    "what is the swara that holds the first position;7\n",
    "what is the top listed player;7\n",
    "what is the smallest matches amount;4\n",
    "\"\"\".split('\\n')\n",
    "\n",
    "collect6selecteq = \"\"\"what are the number of league_apps ted_davis has;6\n",
    "what are the number of pga that zimbabwe has;5\n",
    "what are the number of pga winning golfers that zimbabwe has;5;t\n",
    "who only won 13 silver medals;0;t\n",
    "what is the number of wins for maynooth;3\n",
    "what was the number of silver medals the ivory_coast won;0;t\n",
    "how many u.s._open wins does fiji have;5;t\n",
    "how many u.s._open does fiji have;5\n",
    "which country won only 1 medal, a bronze medal;0;t\n",
    "which ranking is mexico;0\n",
    "how many silver medals did brazil received;0;t\n",
    "what country has won no silver medals;0;t\n",
    "what is the number of silver medals did chile win;0;t\n",
    "\"\"\".split('\\n')\n",
    "\n",
    "collect6selectg = \"\"\"\n",
    "name a player that plays in no less than 13 innings;4;t\n",
    "which country was awarded more than 5 silver medals;0;t\n",
    "only team to have more than 30 silver medals;0;t\n",
    "only team to have more than 30 silver;0\n",
    "who won more gold medals than united_states;0;t\n",
    "name a player whose average was above 25;4\n",
    "\"\"\".split('\\n')\n",
    "\n",
    "collect6selectl = \"\"\"\n",
    "name a player that plays in no more than 13 innings;4;t\n",
    "which country was awarded less than 5 silver medals;0;t\n",
    "only team to have less than 30 silver medals;0;t\n",
    "only team to have less than 30 silver;0\n",
    "who won less gold medals than united_states;0;t\n",
    "name a player whose average was below 25;4\n",
    "\"\"\".split('\\n')\n",
    "\n",
    "collect6counteq = \"\"\"\n",
    "how many times has minneapolis been the 2nd_venue;8;t\n",
    "total number of times minneapolis has been the 2nd_venue;8;t\n",
    "total number of times minneapolis was the 2nd_venue;8;t\n",
    "the total number of countries have exactly 1 silver;0\n",
    "how many countries have 20 bronze medals;0;t\n",
    "how many countries have 3 the_open winners;5;t\n",
    "how many countries have 3 the_open;5\n",
    "\"\"\".split('\\n')\n",
    "\n",
    "collect6countl = \"\"\"\n",
    "how many nations got at most 8 silver;0 \n",
    "the total number of countries with less than 7 gold;0\n",
    "how many countries have less than 20 bronze medals;0;t\n",
    "how many countries have less than 20 bronze;0\n",
    "the total amount of nations with less than 5 the_open winners;5;t\n",
    "total amount of nations with less than 5 the_open;5\n",
    "\"\"\".split('\\n')\n",
    "\n",
    "collect6countg = \"\"\"\n",
    "how many countries have more than 20 bronze;0\n",
    "how many countries won more than 3 bronze metals;0;t\n",
    "what is the total amount of nations with more than 5 bronze medals;0;t\n",
    "the total amount of nations with more than 5 bronze;0\n",
    "the total amount of nation with more than 66 the_open winners;5;t\n",
    "how many nations won at least three silver medals;0;t\n",
    "how many nations have at least three silver;0\n",
    "\"\"\".split('\\n')\n",
    "\n",
    "collect6before = \"\"\"\n",
    "which year is previous to 2011;1;t\n",
    "the nation before england;0\n",
    "what swara is above shadja;7\n",
    "what is the name of the swara that come before shatshruti_dhaivata;7;t\n",
    "what is the name of the player that come before ted_tyler;4;t\n",
    "which team was the previous winner before fingal_ravens in 2008;3;t\n",
    "what team comes before confey;3\n",
    "what is the team that comes before confey;3\n",
    "\"\"\".split('\\n')\n",
    "\n",
    "collect6after = \"\"\"\n",
    "the nation after england;0\n",
    "what swara is below shadja;7\n",
    "what is the name of the swara that come after shatshruti_dhaivata;7;t\n",
    "what is the name of the player that come after ted_tyler;4;t\n",
    "which team was the next winner after fingal_ravens in 2008;3;t\n",
    "what team comes after confey;3\n",
    "what is the team that comes after confey;3\n",
    "\"\"\".split('\\n')\n",
    "\n",
    "collect10nestmulti = \"\"\"\n",
    "in what year was the 3rd_venue the same as 2011 2nd_venue;8;t\n",
    "when was the 3rd_venue the same as 2011 2nd_venue;8;t\n",
    "the nation to earn the same number of silver medals as gold medals by chile;0;t\n",
    "which nation earn the same number of silver medals as gold medals by chile;0;t\n",
    "which nation has the same number of silver as gold by chile;0\n",
    "the nation has the same number of silver as gold by chile;0\n",
    "who has the same number of silver as gold by chile;0\n",
    "\"\"\".split('\\n')\n",
    "\n",
    "collect10nestfront = \"\"\"\n",
    "in what year was the 3rd_venue the same as 2011;8;t\n",
    "in what year was the goals the same as 2011;1\n",
    "when was the 3rd_venue the same as 2011;8;t\n",
    "when was the goals the same as 2011;1\n",
    "the nation to earn the same number of silver medals as chile;0;t\n",
    "which nation earn the same number of silver medals as chile;0;t\n",
    "which nation has the same number of silver as chile;0\n",
    "the nation has the same number of silver as chile;0\n",
    "who has the same number of silver as chile;0\n",
    "\"\"\".split('\\n')\n",
    "\n",
    "collect10nestback = \"\"\"\n",
    "the amount of silver metals won by switzerland is the same as was won by which nation;0;t\n",
    "the 2nd_venue in the 2010 is the same as in what year;8;t\n",
    "goals in 2007 is the same as in what year;1\n",
    "the number of goals in 2007 is the same as in what year;1;t\n",
    "\"\"\".split('\\n')\n",
    "\n",
    "collect11sum = \"\"\"\n",
    "how many gold medals did japan and france combined win;0;t\n",
    "number of gold medals did japan and france combined win;0;t\n",
    "how many combined gold medals did japan and france win;0;t\n",
    "how many combined gold did japan and france have;0\n",
    "the combined amount of gold did japan and france have;0\n",
    "sum of gold of japan and france;0\n",
    "what is the sum of gold of japan and france;0\n",
    "how many gold did japan and france combined have;0\n",
    "how many innings did bill_roe and ted_tyler have in total;4\n",
    "what is innings did bill_roe and ted_tyler have in total;4\n",
    "\"\"\".split('\\n')\n",
    "\n",
    "collect11diff = \"\"\"\n",
    "what is the difference in gold between cuba and mexico;0\n",
    "the difference of gold between cuba and mexico;0\n",
    "what was the difference between the gold count of brazil and argentina;0\n",
    "difference between the gold count of brazil and argentina;0\n",
    "difference of the amount of gold between brazil and argentina;0\n",
    "how many more gold medals has nepal won than pakistan;0;t\n",
    "how many gold nepal has over pakistan;0\n",
    "number of gold nepal has over pakistan;0\n",
    "the number of gold nepal has over pakistan;0\n",
    "the amount of gold nepal has over pakistan;0\n",
    "\"\"\".split('\\n')\n",
    "\n",
    "# [check] Delete 7\n",
    "# How to deal with no/not which indicates zero?\n",
    "# [check] The currect augmentation directly copy field name, could extend to query words\n",
    "# [check] even the field not shown in the query, the current algorithm still works\n",
    "\n",
    "# print collect6select\n",
    "# print collect4max\n",
    "\n",
    "lo2sum = 'sum <field>:0'\n",
    "lo2avg = 'avg <field>:0'\n",
    "lo4max = 'select <field>:0 argmax <field>:1'\n",
    "lo4min = 'select <field>:0 argmin <field>:1'\n",
    "lo4max_1 = 'select <field>:0 argmax <field>:0'\n",
    "lo4min_1 = 'select <field>:0 argmin <field>:0'\n",
    "lo6selecteq = 'select <field>:0 where <field>:1 equal <value>:1'\n",
    "lo6selectl = 'select <field>:0 where <field>:1 less <value>:1'\n",
    "lo6selectg = 'select <field>:0 where <field>:1 greater <value>:1'\n",
    "lo6counteq = 'count <field>:0 where <field>:1 equal <value>:1'\n",
    "lo6countl = 'count <field>:0 where <field>:1 less <value>:1'\n",
    "lo6countg = 'count <field>:0 where <field>:1 greater <value>:1'\n",
    "lo6before = 'select <field>:0 prev <field>:0 equal <value>:0'\n",
    "lo6after = 'select <field>:0 next <field>:0 equal <value>:0'\n",
    "lo10nestmulti = 'select <field>:0 where <field>:1 equal <field>:2 where <field>:0 equal <value>:0'\n",
    "lo10nestfront = 'select <field>:0 where <field>:1 equal <field>:1 where <field>:0 equal <value>:0'\n",
    "lo10nestback = 'select <field>:1 where <field>:0 equal <field>:0 where <field>:1 equal <value>:1'\n",
    "lo11sum = 'sum <field>:0 where <field>:1 equal <value>:1 and where <field>:1 equal <value>:1'\n",
    "lo11diff = 'diff <field>:0 where <field>:1 equal <value>:1 and where <field>:1 equal <value>:1'\n",
    "\n",
    "\n",
    "main_config = tu.Config()\n",
    "schema_collect = main_config.schema_collect\n",
    "parser = stanford.StanfordParser(model_path='/Users/richard_xiong/Documents/DeepLearningMaster/deep_parser/englishPCFG.ser.gz')\n",
    "\n",
    "# print field_corr\n",
    "# print value_corr \n",
    "# print quTemp\n",
    "# print lo6select"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** New query ***\n",
      "the amount of silver metals won by switzerland is the same as was won by which nation\n",
      "['<field>', 'Silver']\n",
      "['<field>', 'Nation']\n",
      "['<value>', 'Nation']\n",
      "[(3, 0)]\n",
      "[]\n",
      "[(16, 1)]\n",
      "[]\n",
      "['<field>', '0']\n",
      "['<value>', '1']\n",
      "['<field>', '1']\n",
      "[(3, 0), (16, 1)] [(7, 1)]\n",
      "['<field>', '1']\n",
      "['<field>', '0']\n",
      "['<field>', '0']\n",
      "['<field>', '1']\n",
      "['<value>', '1']\n",
      "[(1, 1), (3, 0), (5, 0), (7, 1)] [(9, 1)]\n",
      "['Bronze', 'Nation']\n",
      "['Silver', 'Nation']\n",
      "['Gold', 'Nation']\n",
      "*** New query ***\n",
      "the 2nd_venue in the 2010 is the same as in what year\n",
      "['<field>', '2nd_Venue']\n",
      "['<field>', 'Year']\n",
      "['<value>', 'Year']\n",
      "[(11, 1)]\n",
      "[]\n",
      "[(1, 0)]\n",
      "[]\n",
      "['<field>', '0']\n",
      "['<value>', '1']\n",
      "['<field>', '1']\n",
      "[(1, 0), (11, 1)] [(4, 1)]\n",
      "['<field>', '1']\n",
      "['<field>', '0']\n",
      "['<field>', '0']\n",
      "['<field>', '1']\n",
      "['<value>', '1']\n",
      "[(1, 1), (3, 0), (5, 0), (7, 1)] [(9, 1)]\n",
      "['2nd_Venue', 'Year']\n",
      "['5th_Venue', 'Year']\n",
      "['4th_Venue', 'Year']\n",
      "['3rd_Venue', 'Year']\n",
      "['6th_Venue', 'Year']\n",
      "['1st_Venue', 'Year']\n",
      "*** New query ***\n",
      "goals in 2007 is the same as in what year\n",
      "['<field>', 'Goals']\n",
      "['<field>', 'Year_inducted']\n",
      "['<value>', 'Year_inducted']\n",
      "[(0, 0), (9, 1)]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "['<field>', '0']\n",
      "['<value>', '1']\n",
      "['<field>', '1']\n",
      "[(0, 0), (9, 1)] [(2, 1)]\n",
      "['<field>', '1']\n",
      "['<field>', '0']\n",
      "['<field>', '0']\n",
      "['<field>', '1']\n",
      "['<value>', '1']\n",
      "[(1, 1), (3, 0), (5, 0), (7, 1)] [(9, 1)]\n",
      "['Apps', 'Year_inducted']\n",
      "['Goals', 'Year_inducted']\n",
      "['Total_no._of_seats_in_Assembly', 'Year_of_Election']\n",
      "['No._of_candidates', 'Year_of_Election']\n",
      "['No._of_elected', 'Year_of_Election']\n",
      "['Prices', 'Years_won']\n",
      "['Wins', 'Years_won']\n",
      "['Areas', 'Years_won']\n",
      "*** New query ***\n",
      "the number of goals in 2007 is the same as in what year\n",
      "['<field>', 'Goals']\n",
      "['<field>', 'Year_inducted']\n",
      "['<value>', 'Year_inducted']\n",
      "[(3, 0), (12, 1)]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "['<field>', '0']\n",
      "['<value>', '1']\n",
      "['<field>', '1']\n",
      "[(3, 0), (12, 1)] [(5, 1)]\n",
      "['<field>', '1']\n",
      "['<field>', '0']\n",
      "['<field>', '0']\n",
      "['<field>', '1']\n",
      "['<value>', '1']\n",
      "[(1, 1), (3, 0), (5, 0), (7, 1)] [(9, 1)]\n",
      "['Apps', 'Year_inducted']\n",
      "['Goals', 'Year_inducted']\n"
     ]
    }
   ],
   "source": [
    "def main(collect, logic):\n",
    "    ''' for certain logic form, we have lines from collect files\n",
    "        return --- queryCollect, logicCollect, fieldCollect\n",
    "    '''\n",
    "    queryCollect, logicCollect, fieldCollect = [], [], []\n",
    "    for line in collect:\n",
    "        # for each line, we parse the query, schema_idx(, and special_code)\n",
    "        reference = line.split(';')\n",
    "        if len(reference) < 2:\n",
    "            continue\n",
    "        query = reference[0]\n",
    "        schema_idx = int(reference[1])\n",
    "    \n",
    "        print '*** New query ***'\n",
    "        print query\n",
    "        #tagging\n",
    "        tagged2, field_corr, value_corr, quTemp, _ = \\\n",
    "                tg.sentTagging_tree(parser, query, ' '.join(schema_collect[schema_idx]))\n",
    "        #converting\n",
    "        if len(reference) > 2:\n",
    "            field_corr_new, schema_aug = schemaRecommend(schema_idx, field_corr, True)\n",
    "        else:\n",
    "            field_corr_new, schema_aug = schemaRecommend(schema_idx, field_corr, False)\n",
    "        #augmenting\n",
    "        queryOne, logicOne, fieldOne = augment(quTemp, logic, field_corr_new, schema_aug)\n",
    "        #extending collections\n",
    "        queryCollect.extend(queryOne)\n",
    "        logicCollect.extend(logicOne)\n",
    "        fieldCollect.extend(fieldOne)\n",
    "    return queryCollect, logicCollect, fieldCollect\n",
    "\n",
    "queryCollect, logicCollect, fieldCollect = main(collect10nestback, lo10nestback)\n",
    "#main(collect6selectg, lo6selectg) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "f_qu = open('new.qu','a+')\n",
    "f_lo = open('new.lo','a+')\n",
    "f_fi = open('new.fi','a+')\n",
    "\n",
    "for i in range(len(queryCollect)):\n",
    "    f_qu.write(queryCollect[i]+'\\n')\n",
    "    f_lo.write(logicCollect[i]+'\\n')\n",
    "    f_fi.write(fieldCollect[i]+'\\n')\n",
    "\n",
    "f_qu.close()\n",
    "f_lo.close()\n",
    "f_fi.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
