{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data augmentation\n",
    "\n",
    "## 1 Current data statistics\n",
    "\n",
    "### We read in the files of queries, logical forms, and schema, and categorize them by length; within the same length, there would be subcategories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "length = 2, total examples: 2\n",
      "length = 4, total examples: 156\n",
      "length = 6, total examples: 1253\n",
      "length = 7, total examples: 4\n",
      "length = 8, total examples: 624\n",
      "length = 10, total examples: 687\n",
      "length = 11, total examples: 697\n",
      "length = 12, total examples: 488\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "import math\n",
    "\n",
    "logic_category_len = dict()\n",
    "query_len = dict()\n",
    "schema_len = dict()\n",
    "with open('./rand.lo') as f_lo:\n",
    "    with open('./rand.qu') as f_qu:\n",
    "        with open('./rand.fi') as f_fi:\n",
    "            logic_line, query_line, schema_line = f_lo.readline(), f_qu.readline(), f_fi.readline()\n",
    "            while logic_line and query_line and schema_line:\n",
    "                logic = logic_line.split()\n",
    "#                 if len(logic) == 13:\n",
    "#                     if logic[4] == 'less':\n",
    "#                         logic[0] = 'argmax'\n",
    "#                     else:\n",
    "#                         logic[0] = 'argmin'\n",
    "#                     logic.insert(2, logic[3])\n",
    "                length = len(logic)\n",
    "#                 if length ==0:\n",
    "#                     continue\n",
    "                if length not in logic_category_len:\n",
    "                    logic_category_len[length] = []\n",
    "                    query_len[length] = []\n",
    "                    schema_len[length] = []\n",
    "                logic_category_len[length].append(logic_line)\n",
    "                query_len[length].append(query_line)\n",
    "                schema_len[length].append(schema_line)\n",
    "                logic_line, query_line, schema_line = f_lo.readline(), f_qu.readline(), f_fi.readline()\n",
    "for key in logic_category_len.keys():\n",
    "    value = logic_category_len[key]\n",
    "    print 'length = %d, total examples: %d' %(key, len(value))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Have a look at the data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "what is the difference between the nations with the most and least amount of bronze medals\n",
      "\n",
      "how long in years has the this world series been occurring\n",
      "\n",
      "what is the difference between the nations with the most and least amount of gold medals\n",
      "\n",
      "what is the difference between the nations with the most and least amount of silver medals\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(logic_category_len[7])):\n",
    "    print query_len[7][i]\n",
    "    #print logic_category_len[14][i]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now we collect all different schema in a list for later use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nation Rank Gold Silver Bronze Total\n",
      "\n",
      "Name Year_inducted Position Apps Goals\n",
      "\n",
      "Year 1st_Venue 2nd_Venue 3rd_Venue 4th_Venue 5th_Venue 6th_Venue\n",
      "\n",
      "Player Matches Innings Runs Average 100s 50s Games_Played Field_Goals Free_Throws Points\n",
      "\n",
      "Team County Wins Years_won Areas Prices\n",
      "\n",
      "Country Masters U.S._Open The_Open PGA Total\n",
      "\n",
      "Swara Position Short_name Notation Mnemonic\n",
      "\n",
      "State No._of_candidates No._of_elected Total_no._of_seats_in_Assembly Year_of_Election\n",
      "\n",
      "Discipline Amanda Bernie Javine_H Julia Michelle\n",
      "\n",
      "Nation Name Position League_Apps League_Goals FA_Cup_Apps FA_Cup_Goals Total_Apps Total_Goals\n",
      "\n",
      "Menteri_Besar Took_office Left_office Party\n",
      "\n"
     ]
    }
   ],
   "source": [
    "schema_collect = []\n",
    "with open('./rand.fi') as f_fi:\n",
    "    for line in f_fi:\n",
    "        if line in schema_collect:\n",
    "            continue\n",
    "        schema_collect.append(line)\n",
    "    \n",
    "for schema in schema_collect:\n",
    "    print schema"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2 Data Preparation and Generation\n",
    "\n",
    "### Next we do some data generation, the first goal is to double our current data size (8k~10k) \n",
    "\n",
    "As we previously did some work in the file ./data_prep/categorization.txt, we have several different sentences for a single length category. For each sentence structure, we first see whether it could applied to all or several schema, or just a single schema; then we tag each sentence, and for 'field' and 'value', we do data recombination for both query and logical forms; finally we add noise and replace synonyms in the queries to further complicate the sentence structrue.\n",
    "\n",
    "Let's start with the easiest length = 4:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Importing GloVe pretrained word vectors\n",
      "\t\treading 10000 lines from GloVe file\n",
      "\t\treading 20000 lines from GloVe file\n",
      "\t\treading 30000 lines from GloVe file\n",
      "\t\treading 40000 lines from GloVe file\n",
      "\t\treading 50000 lines from GloVe file\n",
      "Replacing GloVe word vectors as initialization\n"
     ]
    }
   ],
   "source": [
    "import os,sys,inspect\n",
    "\n",
    "import tagger as tg\n",
    "import tag_utils as tu\n",
    "from nltk.parse import stanford\n",
    "from nltk import tree\n",
    "\n",
    "currentdir = os.path.dirname(os.path.abspath(inspect.getfile(inspect.currentframe())))\n",
    "parentdir = os.path.dirname(currentdir)\n",
    "sys.path.insert(0,parentdir)\n",
    "os.environ['STANFORD_PARSER'] = '/Users/richard_xiong/Documents/DeepLearningMaster/deep_parser'\n",
    "os.environ['STANFORD_MODELS'] = '/Users/richard_xiong/Documents/DeepLearningMaster/deep_parser'\n",
    "\n",
    "parser = stanford.StanfordParser(model_path='/Users/richard_xiong/Documents/DeepLearningMaster/deep_parser/englishPCFG.ser.gz')\n",
    "\n",
    "#parsequery = \"which nation has less than 6 <field:1> but its <field:2> medals are more than 14 \"\n",
    "#parsequery = \"when the <field:1> was beijing and <field:2> was dubai , which city was the most recent <field:4>\"\n",
    "#parsequery = \"for <field:0> with more than 400 <field:1> and <field:2> less than 14 , <field:0> has the most <field:3>\"\n",
    "# parsequery = \"which state had the largest <field:1>, and its <field:2> are within 12 and 15\"\n",
    "# dependency_tree = parser.raw_parse_sents(('Hello, My name is Melroy', parsequery))\n",
    "\n",
    "# for line in dependency_tree[1]:\n",
    "#     line.draw()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to find which value corresponds to which field, we need to first find:\n",
    "1. the lowest common ancestor for each (value, field) pairs\n",
    "2. for each value, all different ancestors are belong to different levels, the deepest one, which should be the subtree for all the others, would contain the correspondence pair\n",
    "\n",
    "Possible functions:\n",
    "\n",
    "leaf_treeposition(self, index) ---> return: The tree position of the ``index``-th leaf in this\n",
    "            tree.  I.e., if ``tp=self.leaf_treeposition(i)``, then\n",
    "            ``self[tp]==self.leaves()[i]``.\n",
    "\n",
    "treeposition_spanning_leaves(self, start, end) ---> The tree position of the lowest descendant of this\n",
    "            tree that dominates ``self.leaves()[start:end]``.\n",
    "\n",
    "convert(cls, tree) ---> to subtype of Tree, say, ParentTree\n",
    "\n",
    "e.g.\n",
    "(0, 0, 1, 0, 0, 1, 0)\n",
    "(0, 0, 1, 0, 1, 1, 0, 0)\n",
    "(0, 0, 1, 2, 0, 0, 0)\n",
    "(0, 0, 1, 2, 1, 1, 0, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nation Rank Gold Silver Bronze Total\n",
      "\n",
      "Name Year_inducted Position Apps Goals\n",
      "\n",
      "State Year_of_Election No._of_candidates No._of_elected Total_no._of_seats_in_Assembly \n",
      "\n",
      "Team Years_won County Wins Areas Prices \n",
      "\n",
      "Player Matches Innings Runs Average 100s 50s Games_Played Field_Goals Free_Throws Points \n",
      "\n",
      "Country Masters U.S._Open The_Open PGA Total\n",
      "\n",
      "Discipline Amanda Bernie Javine_H Julia Michelle \n",
      "\n",
      "Nation Name Position League_Apps League_Goals FA_Cup_Apps FA_Cup_Goals Total_Apps Total_Goals \n",
      "\n",
      "Swara Position Short_name Notation Mnemonic \n",
      "\n",
      "Year 1st_Venue 2nd_Venue 3rd_Venue 4th_Venue 5th_Venue 6th_Venue \n",
      "\n",
      "Menteri_Besar Took_office Left_office Party\n",
      "\n"
     ]
    }
   ],
   "source": [
    "schema_collect[2] = \"State Year_of_Election No._of_candidates No._of_elected Total_no._of_seats_in_Assembly \\n\"\n",
    "schema_collect[7] = \"Year 1st_Venue 2nd_Venue 3rd_Venue 4th_Venue 5th_Venue 6th_Venue \\n\"\n",
    "schema_collect[3] = \"Team Years_won County Wins Areas Prices \\n\"\n",
    "schema_collect[4] = \"Player Matches Innings Runs Average 100s 50s Games_Played Field_Goals Free_Throws Points \\n\"\n",
    "\n",
    "schema_collect[6] = \"Discipline Amanda Bernie Javine_H Julia Michelle \\n\"\n",
    "schema_collect[8] = \"Swara Position Short_name Notation Mnemonic \\n\"\n",
    "schema_collect[7] = \"Nation Name Position League_Apps League_Goals FA_Cup_Apps FA_Cup_Goals Total_Apps Total_Goals \\n\"\n",
    "schema_collect[9] = \"Year 1st_Venue 2nd_Venue 3rd_Venue 4th_Venue 5th_Venue 6th_Venue \\n\"\n",
    "\n",
    "for schema in schema_collect:\n",
    "    print schema"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conventions \n",
    "1. \"o\" stands for \"ordinal\" values, refering to schema_collect[0:4]\n",
    "2. \"n\" stands for \"numerical\" values, refering to schema_collect[4:8]\n",
    "3. \"s\" stands for \"string\" values, refering to schema_collect[7:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['which country has the most pga championships', 'which country had the most number of wins', 'which country won the largest haul of bronze medals', 'who was the last de player', 'which nation received the largest amount of gold medals', 'the team with the most gold medals', 'which nation was ranked last', 'the country that won the most medals was', 'what is the largest matches amount']\n",
      "Country Masters U.S._Open The_Open PGA Total\n",
      "which country has the most pga championships\n",
      "['<field>', 'Country']\n",
      "['<field>', 'PGA']\n",
      "[(5, 1)]\n",
      "[]\n",
      "[(1, 0)]\n",
      "[]\n",
      "Country PGA\n",
      "<nan> <nan>\n",
      "which <field>:0 has the most <field>:1 championships\n",
      "select <field>:0 argmax <field>:1\n"
     ]
    }
   ],
   "source": [
    "collect4max = \"\"\"which country has the most pga championships\n",
    "which country had the most number of wins\n",
    "which country won the largest haul of bronze medals\n",
    "who was the last de player\n",
    "which nation received the largest amount of gold medals\n",
    "the team with the most gold medals\n",
    "which nation was ranked last\n",
    "the country that won the most medals was\n",
    "what is the largest matches amount\"\"\".split('\\n')\n",
    "\n",
    "collect4min = \"\"\"who was the first nation\n",
    "what is the name of the first nation on this chart\n",
    "what is the name of the swara that holds the first position\n",
    "which country had the least bronze medals\n",
    "who scored the least on whitewater_kayak\n",
    "which state has the top no._of_elected amount\n",
    "who was the top scorer in innings\n",
    "what is the top listed player\n",
    "who is the top ranked nation\"\"\".split('\\n')\n",
    "\n",
    "print collect4max\n",
    "\n",
    "lo4max = 'select <field>:0 argmax <field>:1'\n",
    "lo4min = 'select <field>:0 argmin <field>:1'\n",
    "\n",
    "print schema_collect[5], collect4max[0]\n",
    "tagged2, field_corr, value_corr, quTemp, _ = \\\n",
    "            tg.sentTagging_tree(parser, collect4max[0], schema_collect[5])\n",
    "print field_corr\n",
    "print value_corr \n",
    "print quTemp\n",
    "print lo4max"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Note:\n",
    "Each sentence could then be turned into a query tempelate after tagging. Now we have the logical template, query template, and several available schema (annotated by 'o' 'n' 's'), so combined with the field_corr and value_corr files we should be able to generate multiple sentences according to several schema."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['<field>', '0']\n",
      "['<field>', '1']\n",
      "[(1, 0), (5, 1)] []\n",
      "['<field>', '0']\n",
      "['<field>', '1']\n",
      "[(1, 0), (3, 1)] []\n",
      "=== 0 schema ===\n",
      "['Nation', 'Rank', 'Gold', 'Silver', 'Bronze', 'Total']\n",
      "[{'Nation': ['Mongolia', 'US', 'Hungary', 'Bahamas', 'Austria']}, {'Bronze': [41, 71, 14, 17, 24], 'Silver': [85, 29, 6, 89, 95], 'Gold': [13, 22, 13, 37, 51]}]\n",
      "=== 1 schema ===\n",
      "['Name', 'Year_inducted', 'Position', 'Apps', 'Goals']\n",
      "[{'Position': ['Defender', 'Forward', 'QB', 'Goalkeeper', 'DE'], 'Name': ['Ross_Jenkins', 'Ernie_Islip', 'Jack_Byers', 'Harry_Brough', 'Robert_Jones']}, {'Apps': [94, 40, 8, 8, 34], 'Goals': [8, 18, 64, 27, 49]}]\n",
      "=== 2 schema ===\n",
      "['State', 'Year_of_Election', 'No._of_candidates', 'No._of_elected', 'Total_no._of_seats_in_Assembly']\n",
      "[{'State': ['West_Bengal', 'Manipur', 'Andhra_Pradesh', 'Goa', 'Florida']}, {'Total_no._of_seats_in_Assembly': [20, 75, 6, 93, 88], 'No._of_candidates': [45, 56, 54, 39, 43], 'No._of_elected': [51, 39, 40, 36, 85]}]\n",
      "=== 3 schema ===\n",
      "['Team', 'Years_won', 'County', 'Wins', 'Areas', 'Prices']\n",
      "[{'County': ['Louth', 'Dublin', 'Kildare', 'Laois', 'Wicklow'], 'Team': ['Ireland', 'Spain', 'Cyprus', 'Mexico', 'Maynooth']}, {'Prices': [28, 62, 72, 9, 40], 'Wins': [52, 80, 42, 76, 29], 'Areas': [38, 1, 7, 83, 98]}]\n",
      "=== 4 schema ===\n",
      "['Player', 'Matches', 'Innings', 'Runs', 'Average', '100s', '50s', 'Games_Played', 'Field_Goals', 'Free_Throws', 'Points']\n",
      "[{'Player': ['Crescens_Robinson', 'Clyde_Alwood', 'Gordon_Otto', 'Lionel_Palairet', 'Ernest_McKay']}, {'Innings': [16, 60, 50, 85, 77], 'Runs': [17, 78, 98, 85, 6], 'Matches': [53, 3, 87, 99, 8], 'Field_Goals': [43, 5, 14, 7, 23], 'Free_Throws': [51, 89, 60, 4, 62], 'Points': [14, 49, 5, 21, 74], 'Games_Played': [12, 19, 25, 63, 88], '100s': [63, 50, 88, 79, 28], '50s': [60, 63, 80, 84, 86]}]\n",
      "=== 5 schema ===\n",
      "['Country', 'Masters', 'U.S._Open', 'The_Open', 'PGA', 'Total']\n",
      "[{'Country': ['Switzerland', 'Austria', 'Great_Britain', 'Taiwan', 'Belarus']}, {'U.S._Open': [12, 43, 72, 2, 61], 'Masters': [91, 81, 73, 19, 71], 'The_Open': [30, 45, 92, 47, 81], 'PGA': [41, 12, 59, 59, 35]}]\n",
      "=== 6 schema ===\n",
      "['Discipline', 'Amanda', 'Bernie', 'Javine_H', 'Julia', 'Michelle']\n",
      "[{'Discipline': ['Curling', 'Whitewater_Kayak', 'Hammer', 'Swimming', 'Cycling']}, {'Michelle': [88, 44, 66, 70, 78], 'Amanda': [31, 24, 55, 93, 93], 'Julia': [93, 57, 4, 91, 53], 'Javine_H': [82, 42, 9, 21, 78], 'Bernie': [67, 85, 75, 98, 47]}]\n",
      "=== 7 schema ===\n",
      "['Nation', 'Name', 'Position', 'League_Apps', 'League_Goals', 'FA_Cup_Apps', 'FA_Cup_Goals', 'Total_Apps', 'Total_Goals']\n",
      "[{'Position': ['DE', 'Defender', 'QB', 'TE', 'CB'], 'Name': ['Colin_McKay', 'Duncan_Welbourne', 'Luther_Blissett', 'Jack_Byers', 'James_Wood'], 'Nation': ['Romania', 'Great_Britain', 'South_Korea', 'Uzbekistan', 'Belarus']}, {'Total_Apps': [22, 54, 14, 35, 15], 'FA_Cup_Apps': [23, 57, 70, 84, 95], 'Total_Goals': [74, 75, 30, 73, 10], 'FA_Cup_Goals': [5, 18, 33, 21, 49], 'League_Apps': [73, 8, 39, 1, 21], 'League_Goals': [17, 16, 20, 67, 63]}]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "([], [], [])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def schemaRecommend(field_corr_old, special_code):\n",
    "    ''' From the old generated field correspondence (string), transform to a new field correspondence, \n",
    "        represented by a list value_types, and from the set of value types to get the possible schemas \n",
    "        (PLURALS) that could use for augmentation later (check that all the types in field_corr_new \n",
    "        should be in each schema)\n",
    "        arguments --- special_code: might be used to indicate that the schema is not tranferrable.\n",
    "        return --- field_corr: a list of value_types\n",
    "                   schemas: several schema that the template could augment to, each contain all the\n",
    "                   value_types needed; also see 'special_code'.\n",
    "    '''\n",
    "    return field_corr_new, schemas\n",
    "\n",
    "field_corr_new = ['string', 'int']\n",
    "schema_aug = schema_collect[0:8]\n",
    "\n",
    "def augment4max(quTemp, loTemp, field_corr, schema_aug):\n",
    "    ''' Data augmentation from a pair of query template and logical template\n",
    "        arguments --- field_corr: a list of value_types e.g. ['string','ordinal','int'], each idx should \n",
    "                      correspond to the postion in the templates\n",
    "                      schemas: PLURALS HERE! several schemas that the template could augment to.\n",
    "        return --- collections of queries, logics, and fields\n",
    "    '''\n",
    "    queryCollect, logicCollect, fieldCollect = [], [], []\n",
    "    config = tu.Config()\n",
    "    \n",
    "    # Step 1: preparation\n",
    "    query = quTemp.split()\n",
    "    logic = loTemp.split()\n",
    "    qu_field = []  # positions of field in query\n",
    "    qu_value = []  # positions of value in query\n",
    "    lo_field = []  # positions of field in logic\n",
    "    lo_value = []  # positions of value in logic\n",
    "    for i in range(len(query)):\n",
    "        reference = query[i].split(':')\n",
    "        if len(reference) == 1:\n",
    "            continue\n",
    "        print reference\n",
    "        idx = int(reference[1])\n",
    "        if reference[0] == '<field>':\n",
    "            qu_field.append((i, idx))\n",
    "        else:\n",
    "            qu_value.append((i, idx))\n",
    "    print qu_field, qu_value\n",
    "    for i in range(len(logic)):\n",
    "        reference = logic[i].split(':')\n",
    "        if len(reference) == 1:\n",
    "            continue\n",
    "        print reference\n",
    "        idx = int(reference[1])\n",
    "        if reference[0] == '<field>':\n",
    "            lo_field.append((i, idx))\n",
    "        else:\n",
    "            lo_value.append((i, idx))\n",
    "    print lo_field, lo_value\n",
    "    \n",
    "    # Step 2: augment to different schemas\n",
    "    for j in range(len(schema_aug)):\n",
    "        field_corr_dicts = []\n",
    "        print '=== %d schema ===' %j\n",
    "        schema = schema_aug[j].split()\n",
    "        print schema\n",
    "        # because there could be multiple same-type fields in one sentences, we go over field_corr\n",
    "        for k in range(len(field_corr)):\n",
    "            field_corr_dict = dict()\n",
    "            for i in range(len(schema)):\n",
    "                field = schema[i]\n",
    "                #print field\n",
    "                if schema[i] == 'Total' or schema[i] == 'Average':\n",
    "                    continue\n",
    "                value_type = config.field2word[schema[i]]['value_type']\n",
    "                #print value_type\n",
    "                if value_type == field_corr[k]:\n",
    "                    if value_type == 'string':\n",
    "                        #field_corr_dict[field] = config.field2word[schema[i]]['value_range']\n",
    "                        field_corr_dict[field] = random.sample(config.field2word[schema[i]]['value_range'], 5)\n",
    "                    elif value_type == 'int':\n",
    "                        field_corr_dict[field] = [random.randint(1, 99) for i in range(5)]\n",
    "                    elif value_type == 'date':\n",
    "                        field_corr_dict[field] = [random.randint(1970, 2010) for i in range(5)]\n",
    "                    elif value_type == 'ordinal':\n",
    "                        field_corr_dict[field] = [random.randint(1, 9) for i in range(5)]\n",
    "            field_corr_dicts.append(field_corr_dict)\n",
    "        print field_corr_dicts \n",
    "        # now the list of dicts [{str_field1:[], str_field2:[], ...}, {int_field1:[], int_field2:[], ...}]\n",
    "    return queryCollect, logicCollect, fieldCollect\n",
    "\n",
    "augment4max(quTemp, lo4max, field_corr_new, schema_aug)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
