{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data augmentation\n",
    "\n",
    "## 1 Current data statistics\n",
    "\n",
    "### We read in the files: \n",
    "of queries, logical forms, and schema, and categorize them by length; within the same length, there would be subcategories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "length = 2, total examples: 2\n",
      "length = 4, total examples: 156\n",
      "length = 6, total examples: 1253\n",
      "length = 7, total examples: 4\n",
      "length = 8, total examples: 624\n",
      "length = 10, total examples: 687\n",
      "length = 11, total examples: 697\n",
      "length = 12, total examples: 488\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "import math\n",
    "\n",
    "logic_category_len = dict()\n",
    "query_len = dict()\n",
    "schema_len = dict()\n",
    "with open('./rand.lo') as f_lo:\n",
    "    with open('./rand.qu') as f_qu:\n",
    "        with open('./rand.fi') as f_fi:\n",
    "            logic_line, query_line, schema_line = f_lo.readline(), f_qu.readline(), f_fi.readline()\n",
    "            while logic_line and query_line and schema_line:\n",
    "                logic = logic_line.split()\n",
    "#                 if len(logic) == 13:\n",
    "#                     if logic[4] == 'less':\n",
    "#                         logic[0] = 'argmax'\n",
    "#                     else:\n",
    "#                         logic[0] = 'argmin'\n",
    "#                     logic.insert(2, logic[3])\n",
    "                length = len(logic)\n",
    "#                 if length ==0:\n",
    "#                     continue\n",
    "                if length not in logic_category_len:\n",
    "                    logic_category_len[length] = []\n",
    "                    query_len[length] = []\n",
    "                    schema_len[length] = []\n",
    "                logic_category_len[length].append(logic_line)\n",
    "                query_len[length].append(query_line)\n",
    "                schema_len[length].append(schema_line)\n",
    "                logic_line, query_line, schema_line = f_lo.readline(), f_qu.readline(), f_fi.readline()\n",
    "for key in logic_category_len.keys():\n",
    "    value = logic_category_len[key]\n",
    "    print 'length = %d, total examples: %d' %(key, len(value))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Have a look at the data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "what is the difference between the nations with the most and least amount of bronze medals\n",
      "\n",
      "how long in years has the this world series been occurring\n",
      "\n",
      "what is the difference between the nations with the most and least amount of gold medals\n",
      "\n",
      "what is the difference between the nations with the most and least amount of silver medals\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(logic_category_len[7])):\n",
    "    print query_len[7][i]\n",
    "    #print logic_category_len[14][i]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now we collect all different schema in a list for later use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nation Rank Gold Silver Bronze Total\n",
      "\n",
      "Name Year_inducted Position Apps Goals\n",
      "\n",
      "State Year_of_Election No._of_candidates No._of_elected Total_no._of_seats_in_Assembly \n",
      "\n",
      "Team Years_won County Wins Areas Prices \n",
      "\n",
      "Player Matches Innings Runs Average 100s 50s Games_Played Field_Goals Free_Throws Points \n",
      "\n",
      "Country Masters U.S._Open The_Open PGA Total\n",
      "\n",
      "Discipline Amanda Bernie Javine_H Julia Michelle \n",
      "\n",
      "Nation Name Position League_Apps League_Goals FA_Cup_Apps FA_Cup_Goals Total_Apps Total_Goals \n",
      "\n",
      "Swara Position Short_name Notation Mnemonic \n",
      "\n",
      "Year 1st_Venue 2nd_Venue 3rd_Venue 4th_Venue 5th_Venue 6th_Venue \n",
      "\n",
      "Menteri_Besar Took_office Left_office Party\n",
      "\n"
     ]
    }
   ],
   "source": [
    "schema_collect = []\n",
    "with open('./rand.fi') as f_fi:\n",
    "    for line in f_fi:\n",
    "        if line in schema_collect:\n",
    "            continue\n",
    "        schema_collect.append(line)\n",
    "    \n",
    "schema_collect[2] = \"State Year_of_Election No._of_candidates No._of_elected Total_no._of_seats_in_Assembly \\n\"\n",
    "schema_collect[7] = \"Year 1st_Venue 2nd_Venue 3rd_Venue 4th_Venue 5th_Venue 6th_Venue \\n\"\n",
    "schema_collect[3] = \"Team Years_won County Wins Areas Prices \\n\"\n",
    "schema_collect[4] = \"Player Matches Innings Runs Average 100s 50s Games_Played Field_Goals Free_Throws Points \\n\"\n",
    "\n",
    "schema_collect[6] = \"Discipline Amanda Bernie Javine_H Julia Michelle \\n\"\n",
    "schema_collect[8] = \"Swara Position Short_name Notation Mnemonic \\n\"\n",
    "schema_collect[7] = \"Nation Name Position League_Apps League_Goals FA_Cup_Apps FA_Cup_Goals Total_Apps Total_Goals \\n\"\n",
    "schema_collect[9] = \"Year 1st_Venue 2nd_Venue 3rd_Venue 4th_Venue 5th_Venue 6th_Venue \\n\"\n",
    "\n",
    "for schema in schema_collect:\n",
    "    print schema"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2 Data Preparation and Generation\n",
    "\n",
    "### Next we do some data generation, the first goal is to double our current data size (8k~10k) \n",
    "\n",
    "As we previously did some work in the file ./data_prep/categorization.txt, we have several different sentences for a single length category. For each sentence structure, we first see whether it could applied to all or several schema, or just a single schema; then we tag each sentence, and for 'field' and 'value', we do data recombination for both query and logical forms; finally we add noise and replace synonyms in the queries to further complicate the sentence structrue.\n",
    "\n",
    "Let's start with the easiest length = 4:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Importing GloVe pretrained word vectors\n",
      "\t\treading 10000 lines from GloVe file\n",
      "\t\treading 20000 lines from GloVe file\n",
      "\t\treading 30000 lines from GloVe file\n",
      "\t\treading 40000 lines from GloVe file\n",
      "\t\treading 50000 lines from GloVe file\n",
      "Replacing GloVe word vectors as initialization\n"
     ]
    }
   ],
   "source": [
    "import os,sys,inspect\n",
    "import random\n",
    "import numpy as np\n",
    "\n",
    "import tagger as tg\n",
    "import tag_utils as tu\n",
    "from nltk.parse import stanford\n",
    "from nltk import tree\n",
    "\n",
    "currentdir = os.path.dirname(os.path.abspath(inspect.getfile(inspect.currentframe())))\n",
    "parentdir = os.path.dirname(currentdir)\n",
    "sys.path.insert(0,parentdir)\n",
    "os.environ['STANFORD_PARSER'] = '/Users/richard_xiong/Documents/DeepLearningMaster/deep_parser'\n",
    "os.environ['STANFORD_MODELS'] = '/Users/richard_xiong/Documents/DeepLearningMaster/deep_parser'\n",
    "\n",
    "parser = stanford.StanfordParser(model_path='/Users/richard_xiong/Documents/DeepLearningMaster/deep_parser/englishPCFG.ser.gz')\n",
    "\n",
    "#parsequery = \"which nation has less than 6 <field:1> but its <field:2> medals are more than 14 \"\n",
    "#parsequery = \"when the <field:1> was beijing and <field:2> was dubai , which city was the most recent <field:4>\"\n",
    "#parsequery = \"for <field:0> with more than 400 <field:1> and <field:2> less than 14 , <field:0> has the most <field:3>\"\n",
    "# parsequery = \"which state had the largest <field:1>, and its <field:2> are within 12 and 15\"\n",
    "# dependency_tree = parser.raw_parse_sents(('Hello, My name is Melroy', parsequery))\n",
    "\n",
    "# for line in dependency_tree[1]:\n",
    "#     line.draw()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to find which value corresponds to which field, we need to first find:\n",
    "1. the lowest common ancestor for each (value, field) pairs\n",
    "2. for each value, all different ancestors are belong to different levels, the deepest one, which should be the subtree for all the others, would contain the correspondence pair\n",
    "\n",
    "Possible functions:\n",
    "\n",
    "leaf_treeposition(self, index) ---> return: The tree position of the ``index``-th leaf in this\n",
    "            tree.  I.e., if ``tp=self.leaf_treeposition(i)``, then\n",
    "            ``self[tp]==self.leaves()[i]``.\n",
    "\n",
    "treeposition_spanning_leaves(self, start, end) ---> The tree position of the lowest descendant of this\n",
    "            tree that dominates ``self.leaves()[start:end]``.\n",
    "\n",
    "convert(cls, tree) ---> to subtype of Tree, say, ParentTree\n",
    "\n",
    "e.g.\n",
    "(0, 0, 1, 0, 0, 1, 0)\n",
    "(0, 0, 1, 0, 1, 1, 0, 0)\n",
    "(0, 0, 1, 2, 0, 0, 0)\n",
    "(0, 0, 1, 2, 1, 1, 0, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#field_corr_dicts = [{'County': ['Louth', 'Dublin', 'Kildare', 'Laois', 'Wicklow'], 'Team': ['Ireland', 'Spain', 'Cyprus', 'Mexico', 'Maynooth']}, \\\n",
    "#                    {'Prices': [28, 62, 72, 9, 40], 'Wins': [52, 80, 42, 76, 29], 'Areas': [38, 1, 7, 83, 98]}]\n",
    "\n",
    "def isRepetitive(sequence):\n",
    "    for element in sequence[:-1]:\n",
    "        if element == sequence[-1]:\n",
    "            return True\n",
    "    return False\n",
    "\n",
    "def generateFieldCombs(field_corr_dicts):\n",
    "    ''' If only fields are recombinable'''\n",
    "    list_of_seqs = []\n",
    "    if len(field_corr_dicts) == 1:\n",
    "        # base case:\n",
    "        for key in field_corr_dicts[0].keys():\n",
    "            list_of_seqs.append([key])\n",
    "    else:\n",
    "        # recursive case:\n",
    "        former_seqs = generateFieldCombs(field_corr_dicts[:-1])\n",
    "        for key in field_corr_dicts[-1].keys():\n",
    "            for seq in former_seqs:\n",
    "                newseq = [x for x in seq]\n",
    "                newseq.append(key)\n",
    "                # check new repetitive elements\n",
    "                if not isRepetitive(newseq):\n",
    "                    list_of_seqs.append(newseq)\n",
    "    return list_of_seqs\n",
    "\n",
    "def generateValueCombs(field_corr_dicts, field_combination, qu_value):\n",
    "    ''' Both fields and values are recombinable\n",
    "        arguments --- field_combination: the selected field combination, where the value are to be decided\n",
    "    '''\n",
    "    list_of_seqs = []\n",
    "    if len(qu_value) == 1:\n",
    "        # base case:\n",
    "        _, idx = qu_value[0]  # check position of values\n",
    "        for value in field_corr_dicts[idx][field_combination[idx]]:\n",
    "            list_of_seqs.append([value])\n",
    "    else:\n",
    "        # recursive case:\n",
    "        former_seqs = generateValueCombs(field_corr_dicts, field_combination, qu_value[:-1])\n",
    "        _, idx = qu_value[-1]\n",
    "        for value in field_corr_dicts[idx][field_combination[idx]]:\n",
    "            for seq in former_seqs:\n",
    "                newseq = [x for x in seq]\n",
    "                newseq.append(value)\n",
    "                # check new repetitive elements\n",
    "                if not isRepetitive(newseq):\n",
    "                    list_of_seqs.append(newseq)\n",
    "    return list_of_seqs\n",
    "\n",
    "#print generateFieldCombs(field_corr_dicts)\n",
    "#print generateValueCombs(field_corr_dicts, ['County', 'Wins'], [(2,0), (4,1)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def isContainFieldType(schema_type, field_corr):\n",
    "    ''' To determine whether all the types in field_corr appear in the schema\n",
    "        e.g. field_corr = ['string', 'string', 'int'], an available schema should at least contain\n",
    "        two 'string type' and one 'int' type\n",
    "        arguments --- schema_type: a list of corresponding types of the schema\n",
    "                      field_corr: a list of field types appeared in the query\n",
    "        return --- True or False\n",
    "    '''\n",
    "    small_dict = dict() # for field_corr\n",
    "    big_dict = dict()   # for schema_type\n",
    "    # build dictionaries\n",
    "    for field in field_corr:\n",
    "        if field not in small_dict:\n",
    "            small_dict[field] = 0\n",
    "        small_dict[field] += 1\n",
    "    for field in schema_type:\n",
    "        if field not in big_dict:\n",
    "            big_dict[field] = 0\n",
    "        big_dict[field] += 1\n",
    "    for key in small_dict.keys():\n",
    "        if key not in big_dict:\n",
    "            return False\n",
    "        elif big_dict[key] < small_dict[key]:\n",
    "            return False\n",
    "    return True\n",
    "\n",
    "def schemaRecommend(schema_idx, field_corr_old, special_code=False):\n",
    "    ''' From the old generated field correspondence (string), transform to a new field correspondence, \n",
    "        represented by a list value_types, and from the set of value types to get the possible schemas \n",
    "        (PLURALS) that could use for augmentation later (check that all the types in field_corr_new \n",
    "        should be in each schema)\n",
    "        arguments --- schema_idx: the index number of the original query is based on  \n",
    "                      special_code: might be used to indicate that the schema is not tranferrable. \n",
    "                      default False, means able to generalize to schema that contain corresponding field \n",
    "                      types; if True, means only applicable to original schema.\n",
    "        return --- field_corr_new: a list of value_types\n",
    "                   schemas: several schema that the template could augment to, each contain all the\n",
    "                   value_types needed; also see 'special_code'.\n",
    "    '''\n",
    "    config = tu.Config()  # Contain the schema_collect and schema_collect_type information\n",
    "    field_corr_old = field_corr_old.split()\n",
    "    field_corr_new = ['' for x in field_corr_old]\n",
    "    for i in range(len(field_corr_old)):\n",
    "        field_type = config.field2word[field_corr_old[i]]['value_type']\n",
    "        field_corr_new[i] = field_type\n",
    "    \n",
    "    schemas = []\n",
    "    if special_code:\n",
    "        # only the original schema goes into the next stage\n",
    "        schemas.append(config.schema_collect[schema_idx])\n",
    "        return field_corr_new, schemas\n",
    "    \n",
    "    # length = len(config.schema_collect)\n",
    "    length = 9 # ONLY take the first 9 schema\n",
    "    for j in range(length):\n",
    "        # print '*** schema %d ***' %j\n",
    "        if isContainFieldType(config.schema_collect_type[j], field_corr_new):\n",
    "            schemas.append(config.schema_collect[j])\n",
    "    \n",
    "    return field_corr_new, schemas\n",
    "#schemaRecommend(5, 'PGA Country')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# field_corr_new, schema_aug = schemaRecommend(5, 'PGA Country')\n",
    "# field_corr_new = ['int','string']\n",
    "# schema_aug = main_config.schema_collect[0:8]\n",
    "\n",
    "def augment(quTemp, loTemp, field_corr, schema_aug):\n",
    "    ''' Data augmentation from a pair of query template and logical template\n",
    "        arguments --- field_corr: a list of value_types e.g. ['string','ordinal','int'], each idx should \n",
    "                      correspond to the postion in the templates\n",
    "                      schemas: PLURALS HERE! several schemas that the template could augment to.\n",
    "        return --- collections of queries, logics, and fields\n",
    "    '''\n",
    "    queryCollect, logicCollect, fieldCollect = [], [], []\n",
    "    config = tu.Config()\n",
    "    \n",
    "    # Step 1: preparation\n",
    "    query = quTemp.split()\n",
    "    logic = loTemp.split()\n",
    "    qu_field = []  # positions of field in query\n",
    "    qu_value = []  # positions of value in query\n",
    "    lo_field = []  # positions of field in logic\n",
    "    lo_value = []  # positions of value in logic\n",
    "    for i in range(len(query)):\n",
    "        reference = query[i].split(':')\n",
    "        if len(reference) == 1:\n",
    "            continue\n",
    "        print reference\n",
    "        idx = int(reference[1])\n",
    "        if reference[0] == '<field>':\n",
    "            qu_field.append((i, idx))\n",
    "        else:\n",
    "            qu_value.append((i, idx))\n",
    "    print qu_field, qu_value\n",
    "    for i in range(len(logic)):\n",
    "        reference = logic[i].split(':')\n",
    "        if len(reference) == 1:\n",
    "            continue\n",
    "        print reference\n",
    "        idx = int(reference[1])\n",
    "        if reference[0] == '<field>':\n",
    "            lo_field.append((i, idx))\n",
    "        else:\n",
    "            lo_value.append((i, idx))\n",
    "    print lo_field, lo_value\n",
    "    \n",
    "    # Step 2: augment to different schemas\n",
    "    for j in range(len(schema_aug)):\n",
    "        # Step 2.1: for each schema, build correspondence list of dictionarys: [{}, {}, {}]\n",
    "        field_corr_dicts = []\n",
    "        print '=== %d schema ===' %j\n",
    "        schema = schema_aug[j]\n",
    "        #print schema\n",
    "        # because there could be multiple same-type fields in one sentences, we go over field_corr\n",
    "        for k in range(len(field_corr)):\n",
    "            field_corr_dict = dict()\n",
    "            for i in range(len(schema)):\n",
    "                field = schema[i]\n",
    "                #print field\n",
    "                if schema[i] == 'Total' or schema[i] == 'Average':\n",
    "                    continue\n",
    "                value_type = config.field2word[schema[i]]['value_type']\n",
    "                #print value_type\n",
    "                if value_type == field_corr[k]:\n",
    "                    if value_type == 'string':\n",
    "                        #field_corr_dict[field] = config.field2word[schema[i]]['value_range']\n",
    "                        field_corr_dict[field] = random.sample(config.field2word[schema[i]]['value_range'], 5)\n",
    "                    elif value_type == 'int':\n",
    "                        field_corr_dict[field] = [random.randint(1, 99) for i in range(5)]\n",
    "                    elif value_type == 'date':\n",
    "                        field_corr_dict[field] = [random.randint(1970, 2010) for i in range(5)]\n",
    "                    elif value_type == 'ordinal':\n",
    "                        field_corr_dict[field] = [random.randint(1, 9) for i in range(3)]\n",
    "            field_corr_dicts.append(field_corr_dict)\n",
    "        print field_corr_dicts \n",
    "        # now the list of dicts [{str_field1:[], str_field2:[], ...}, {int_field1:[], int_field2:[], ...}]\n",
    "        \n",
    "        # Step 2.2: Regenerate sentence by filling into the place\n",
    "        field_combinations = generateFieldCombs(field_corr_dicts)\n",
    "        for field_combination in field_combinations:\n",
    "            newquery = [x for x in query]\n",
    "            newlogic = [x for x in logic]\n",
    "            # regenerate query, lower case or query_word\n",
    "            for (posit, idx) in qu_field:\n",
    "                field_info = config.field2word[field_combination[idx]]\n",
    "                if len(field_info['query_word']) > 1:\n",
    "                    pick = random.choice(field_info['query_word'])\n",
    "                    while pick == 'who' or pick == 'when' or pick == 'city':\n",
    "                        pick = random.choice(field_info['query_word'])\n",
    "                    newquery[posit] = pick\n",
    "                else:\n",
    "                    newquery[posit] = field_combination[idx].lower()                \n",
    "            # regenerate logic forms\n",
    "            for (posit, idx) in lo_field:\n",
    "                newlogic[posit] = field_combination[idx]\n",
    "            if len(qu_value) > 0:\n",
    "                value_combinations = generateValueCombs(field_corr_dicts, field_combination, qu_value)\n",
    "                for value_combination in value_combinations:\n",
    "                    #print '*** Value Augmentation ***'\n",
    "                    #print value_combination\n",
    "                    morequery = [x for x in newquery]\n",
    "                    morelogic = [x for x in newlogic]\n",
    "                    for i in range(len(qu_value)):\n",
    "                        morequery[qu_value[i][0]] = value_combination[i].lower()\n",
    "                    for i in range(len(lo_value)):\n",
    "                        morelogic[lo_value[i][0]] = value_combination[i]\n",
    "                    queryCollect.append(' '.join(morequery))\n",
    "                    logicCollect.append(' '.join(morelogic))\n",
    "                    fieldCollect.append(' '.join(schema_aug[j]))\n",
    "                continue\n",
    "            queryCollect.append(' '.join(newquery))\n",
    "            logicCollect.append(' '.join(newlogic))\n",
    "            fieldCollect.append(' '.join(schema_aug[j]))\n",
    "    return queryCollect, logicCollect, fieldCollect, \n",
    "\n",
    "# augment(quTemp, lo6select, field_corr_new, schema_aug)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conventions \n",
    "Each sentence could then be turned into a query tempelate after tagging. Now we have the logical template, query template, and several available schema, so combined with the field_corr and value_corr files we should be able to generate multiple sentences according to several schema."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Country', 'Masters', 'U.S._Open', 'The_Open', 'PGA', 'Total']\n",
      "what are the number of pga winning golfers that zimbabwe has;5;t\n",
      "['<field>', 'PGA']\n",
      "['<value>', 'Country']\n",
      "[(5, 0)]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "PGA Country\n",
      "<nan> zimbabwe\n",
      "what are the number of <field>:0 winning golfers that <value>:1 has;5;t\n",
      "select <field>:0 where <field>:1 equal <value>:1\n"
     ]
    }
   ],
   "source": [
    "collect4max = \"\"\"which country has the most pga;5\n",
    "which country has the most pga championships;5;t\n",
    "which country had the most number of wins;3\n",
    "which country won the largest haul of bronze medals;0;t\n",
    "who was the last de player;7;t\n",
    "which nation received the largest amount of gold medals;0;t\n",
    "the team with the most gold medals;0;t\n",
    "the team with the most gold;0\n",
    "which state has the top no._of_elected amount;2\n",
    "who was the top scorer in innings;4\n",
    "which nation was ranked last;0\n",
    "the country that won the most silver medals was;0\n",
    "the country that won the most silver was;0;t\n",
    "what is the largest matches amount;4\n",
    "\"\"\".split('\\n')\n",
    "\n",
    "collect4min = \"\"\"who was the first nation;0\n",
    "what is the name of the first nation on this chart;0\n",
    "what is the name of the swara that holds the first position;7\n",
    "which country had the least bronze medals;0;t\n",
    "which country had the least bronze;0\n",
    "what is the top listed player;7\n",
    "who is the top ranked nation;0\n",
    "\"\"\".split('\\n')\n",
    "\n",
    "collect6select = \"\"\"what are the number of league_apps ted_davis has;6\n",
    "what are the number of pga that zimbabwe has;5\n",
    "what are the number of pga winning golfers that zimbabwe has;5;t\n",
    "who only won 13 silver medals;0;t\n",
    "which country was awarded more than 5 silver medals;0;t\n",
    "what is the number of wins for maynooth;3\n",
    "what was the number of silver medals the ivory_coast won;0;t\n",
    "only team to have more than 30 silver medals;0;t\n",
    "only team to have more than 30 silver;0\n",
    "how many u.s._open wins does fiji have;5;t\n",
    "how many u.s._open does fiji have;5\n",
    "which country won only 1 medal, a bronze medal;0;t\n",
    "which ranking is mexico;0\n",
    "who won more gold medals than united_states;0;t\n",
    "name a player whose average was above 25;4\n",
    "how many silver medals did brazil received;0;t\n",
    "name a player that play in no more than 13 innings;4;t\n",
    "what country has won no silver medals;0;t\n",
    "before 1990, how many pga were obtained;5;t\n",
    "what's the number of silver medals did chile win;0;t\n",
    "\"\"\".split('\\n')\n",
    "\n",
    "# How to deal with no/not which indicates zero?\n",
    "# [check] The currect augmentation directly copy field name, could extend to query words\n",
    "# [check] even the field not shown in the query, the current algorithm still works\n",
    "\n",
    "# print collect6select\n",
    "# print collect4max\n",
    "\n",
    "lo4max = 'select <field>:0 argmax <field>:1'\n",
    "lo4min = 'select <field>:0 argmin <field>:1'\n",
    "lo6select = 'select <field>:0 where <field>:1 equal <value>:1'\n",
    "\n",
    "main_config = tu.Config()\n",
    "schema_collect = main_config.schema_collect\n",
    "\n",
    "print schema_collect[5] \n",
    "print collect6select[2]\n",
    "tagged2, field_corr, value_corr, quTemp, _ = \\\n",
    "            tg.sentTagging_tree(parser, collect6select[2], ' '.join(schema_collect[5]))\n",
    "print field_corr\n",
    "print value_corr \n",
    "print quTemp\n",
    "print lo6select"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "field_corr_new, schema_aug = schemaRecommend(schema_idx, field_corr_old, special_code)\n",
    "augment(quTemp, lo6select, field_corr_new, schema_aug)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
