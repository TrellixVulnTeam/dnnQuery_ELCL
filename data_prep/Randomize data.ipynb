{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 2099 10415   406 ...,  1761  8490  7321]\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "import os\n",
    "import random\n",
    "import sys\n",
    "import time\n",
    "import re\n",
    "\n",
    "import editdistance as ed\n",
    "import numpy as np\n",
    "\n",
    "Fqu = []\n",
    "Flo = []\n",
    "Ffi = []\n",
    "\n",
    "with open('./rand1.fi') as f_fi:\n",
    "    with open('./rand1.qu') as f_qu:\n",
    "        with open('./rand1.lo') as f_lo:\n",
    "            schema, query, logic = f_fi.readline(), f_qu.readline(), f_lo.readline()\n",
    "            idx = 0\n",
    "            while schema and query and logic:\n",
    "                Fqu.append(query)\n",
    "                Flo.append(logic)\n",
    "                Ffi.append(schema)\n",
    "                schema, query, logic = f_fi.readline(), f_qu.readline(), f_lo.readline()\n",
    "                \n",
    "num = np.random.permutation(len(Fqu))\n",
    "print num\n",
    "f_fi1 = open('./rand.fi', 'w')\n",
    "f_lo1 = open('./rand.lo', 'w')\n",
    "f_qu1 = open('./rand.qu', 'w')\n",
    "\n",
    "for i in range(len(num)):\n",
    "    f_lo1.write(Flo[num[i]])\n",
    "    f_fi1.write(Ffi[num[i]])\n",
    "    f_qu1.write(Fqu[num[i]])\n",
    "\n",
    "f_fi1.close()\n",
    "f_qu1.close()\n",
    "f_lo1.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "f_fi1 = open('../data/rand.fi', 'w')\n",
    "f_lo1 = open('../data/rand.lo', 'w')\n",
    "f_qu1 = open('../data/rand.qu', 'w')\n",
    "\n",
    "for i in range(len(num)):\n",
    "    f_lo1.write(Flo[num[i]])\n",
    "    f_fi1.write(Ffi[num[i]])\n",
    "    f_qu1.write(Fqu[num[i]])\n",
    "\n",
    "f_fi1.close()\n",
    "f_qu1.close()\n",
    "f_lo1.close()\n",
    "\n",
    "f_fi_train = open('../data/rand_train.fi', 'w')\n",
    "f_lo_train = open('../data/rand_train.lo', 'w')\n",
    "f_qu_train = open('../data/rand_train.qu', 'w')\n",
    "f_fi_dev = open('../data/rand_dev.fi', 'w')\n",
    "f_lo_dev = open('../data/rand_dev.lo', 'w')\n",
    "f_qu_dev = open('../data/rand_dev.qu', 'w')\n",
    "f_fi_test = open('../data/rand_test.fi', 'w')\n",
    "f_lo_test = open('../data/rand_test.lo', 'w')\n",
    "f_qu_test = open('../data/rand_test.qu', 'w')\n",
    "\n",
    "for i in range(len(num)):\n",
    "    if i < 8000:\n",
    "        f_lo_train.write(Flo[num[i]])\n",
    "        f_fi_train.write(Ffi[num[i]])\n",
    "        f_qu_train.write(Fqu[num[i]])\n",
    "        continue\n",
    "    if i < 10000:\n",
    "        f_lo_dev.write(Flo[num[i]])\n",
    "        f_fi_dev.write(Ffi[num[i]])\n",
    "        f_qu_dev.write(Fqu[num[i]])\n",
    "        continue\n",
    "    f_lo_test.write(Flo[num[i]])\n",
    "    f_fi_test.write(Ffi[num[i]])\n",
    "    f_qu_test.write(Fqu[num[i]])\n",
    "\n",
    "\n",
    "f_fi_train.close()\n",
    "f_qu_train.close()\n",
    "f_lo_train.close()\n",
    "f_fi_dev.close()\n",
    "f_qu_dev.close()\n",
    "f_lo_dev.close()\n",
    "f_fi_test.close()\n",
    "f_qu_test.close()\n",
    "f_lo_test.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  reading data line 200\n",
      "  reading data line 400\n",
      "  reading data line 600\n",
      "  reading data line 800\n",
      "  reading data line 1000\n",
      "  reading data line 1200\n",
      "  reading data line 1400\n",
      "  reading data line 1600\n",
      "  reading data line 1800\n",
      "  reading data line 2000\n",
      "  reading data line 2200\n",
      "  reading data line 2400\n",
      "  reading data line 2600\n",
      "  reading data line 2800\n",
      "bucket 0: 834\n",
      "bucket 1: 752\n",
      "bucket 2: 1214\n",
      "(4, 5): 5\n",
      "(4, 7): 28\n",
      "(5, 5): 23\n",
      "(5, 7): 39\n",
      "(6, 5): 19\n",
      "(6, 7): 250\n",
      "(7, 3): 1\n",
      "(7, 5): 7\n",
      "(7, 7): 83\n",
      "(7, 11): 5\n",
      "(8, 5): 14\n",
      "(8, 7): 54\n",
      "(8, 9): 63\n",
      "(9, 5): 33\n",
      "(9, 7): 278\n",
      "(9, 9): 27\n",
      "(9, 11): 9\n",
      "(9, 12): 74\n",
      "(10, 5): 6\n",
      "(10, 7): 95\n",
      "(10, 9): 284\n",
      "(10, 11): 28\n",
      "(11, 5): 3\n",
      "(11, 7): 55\n",
      "(11, 8): 1\n",
      "(11, 9): 72\n",
      "(11, 11): 33\n",
      "(11, 12): 216\n",
      "(12, 7): 2\n",
      "(12, 11): 43\n",
      "(12, 13): 27\n",
      "(13, 5): 1\n",
      "(13, 7): 6\n",
      "(13, 12): 155\n",
      "(13, 13): 74\n",
      "(14, 11): 19\n",
      "(14, 12): 21\n",
      "(14, 13): 15\n",
      "(15, 11): 334\n",
      "(15, 12): 42\n",
      "(16, 8): 2\n",
      "(17, 11): 10\n",
      "(17, 13): 235\n",
      "(18, 11): 9\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "import os\n",
    "import random\n",
    "import sys\n",
    "import time\n",
    "import re\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import data_utils_tag\n",
    "\n",
    "#_buckets = [(10, 8), (14, 12), (18, 15), (23, 20)]  \n",
    "# _buckets = [(11, 8), (15, 12), (20, 16), (24, 21)]\n",
    "_buckets = [(10, 8), (15, 12), (19, 16)]\n",
    "max_size = None\n",
    "data_set = [[] for _ in _buckets]\n",
    "stat = dict()\n",
    "\n",
    "with tf.gfile.GFile('../data/rand_train.qu', mode=\"r\") as source_file:\n",
    "    with tf.gfile.GFile('../data/rand_train.lo', mode=\"r\") as target_file:\n",
    "        with tf.gfile.GFile('../data/rand_train.ta', mode=\"r\") as tag_file:\n",
    "            source, target, tag = source_file.readline(), target_file.readline(), tag_file.readline()\n",
    "            counter = 0\n",
    "            while source and target and tag and (not max_size or counter < max_size):\n",
    "                counter += 1\n",
    "                if counter % 200 == 0:\n",
    "                    print(\"  reading data line %d\" % counter)\n",
    "                    sys.stdout.flush()\n",
    "                source_ids = [x for x in source.split()]\n",
    "                target_ids = [x for x in target.split()]\n",
    "                tag_ids = [x for x in tag.split()]\n",
    "                target_ids.append(data_utils_tag.EOS_ID)\n",
    "                if (len(source_ids), len(target_ids)) not in stat:\n",
    "                    stat[(len(source_ids), len(target_ids))] = 0\n",
    "                stat[(len(source_ids), len(target_ids))] += 1\n",
    "                for bucket_id, (source_size, target_size) in enumerate(_buckets):\n",
    "                    if len(source_ids) < source_size and len(target_ids) < target_size:\n",
    "                        data_set[bucket_id].append([source_ids, tag_ids, target_ids])\n",
    "                        break\n",
    "                source, target, tag = source_file.readline(), target_file.readline(), tag_file.readline()\n",
    "\n",
    "print \"bucket 0: %d\" % len(data_set[0])\n",
    "print \"bucket 1: %d\" % len(data_set[1])\n",
    "print \"bucket 2: %d\" % len(data_set[2])\n",
    "#print \"bucket 3: %d\" % len(data_set[3])\n",
    "\n",
    "for (s_size, t_size) in sorted(stat.keys()):\n",
    "    print '(%d, %d): %d' %(s_size, t_size, stat[(s_size, t_size)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
